{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AQePAlbAXq67"
      },
      "outputs": [],
      "source": [
        "import os\n",
<<<<<<< HEAD
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import albumentations as A\n",
        "import matplotlib.pyplot as plt\n",
        "from albumentations.pytorch import ToTensorV2"
=======
        "import sys\n",
        "sys.path.append(\"/home/pervinco/mmsegmentation\")\n",
        "\n",
        "import cv2\n",
        "import yaml\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import albumentations as A\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from mmseg.models import build_segmentor\n",
        "from data_preprocess import load_img_mask, encode_mask, train_img_mask_transform, mosaic_augmentation, spatially_exclusive_pasting"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
<<<<<<< HEAD
=======
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_config_to_yaml(config, save_dir):\n",
        "    with open(f\"{save_dir}/params.yaml\", 'w') as file:\n",
        "        yaml.dump(config, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
      "metadata": {
        "id": "9YpB8T-mXjl_"
      },
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "trainsize = 384\n",
        "\n",
        "class BKpolypDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dir=\"path/to/data\", transform=None):\n",
        "        self.img_path_lst = []\n",
        "        self.dir = dir\n",
        "        self.transform = transform\n",
        "        self.img_path_lst = glob(\"{}/train/*\".format(self.dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_path_lst)\n",
        "\n",
        "    def read_mask(self, mask_path):\n",
        "        image = cv2.imread(mask_path)\n",
        "        image = cv2.resize(image, (trainsize, trainsize))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "        # lower boundary RED color range values; Hue (0 - 10)\n",
        "        lower1 = np.array([0, 100, 20])\n",
        "        upper1 = np.array([10, 255, 255])\n",
        "        # upper boundary RED color range values; Hue (160 - 180)\n",
        "        lower2 = np.array([160,100,20])\n",
        "        upper2 = np.array([179,255,255])\n",
        "        lower_mask = cv2.inRange(image, lower1, upper1)\n",
        "        upper_mask = cv2.inRange(image, lower2, upper2)\n",
        "        red_mask = lower_mask + upper_mask\n",
        "        red_mask[red_mask != 0] = 2\n",
        "        # boundary RED color range values; Hue (36 - 70)\n",
        "        green_mask = cv2.inRange(image, (36, 25, 25), (70, 255,255))\n",
        "        green_mask[green_mask != 0] = 1\n",
        "        full_mask = cv2.bitwise_or(red_mask, green_mask)\n",
        "        full_mask = full_mask.astype(np.uint8)\n",
        "        return full_mask\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_path_lst[idx]\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = cv2.resize(image, (trainsize, trainsize))\n",
        "        label_path = img_path.replace(\"train\", \"train_gt\")\n",
        "        label = self.read_mask(label_path)\n",
        "\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=image, mask=label)\n",
        "            image = transformed[\"image\"]\n",
        "            label = transformed[\"mask\"]\n",
        "        return image, label"
=======
        "class BKAIDataset(Dataset):\n",
        "    def __init__(self, config):\n",
        "        self.data_dir = config[\"data_dir\"]\n",
        "        self.img_size = config[\"img_size\"]\n",
        "        self.spatial_alpha = config[\"spatial_alpha\"]\n",
        "\n",
        "        self.image_dir = f\"{self.data_dir}/train\"\n",
        "        self.mask_dir = f\"{self.data_dir}/train_gt\"\n",
        "\n",
        "        self.image_files = sorted(glob(f\"{self.image_dir}/*.jpeg\"))\n",
        "        self.mask_files = sorted(glob(f\"{self.mask_dir}/*.jpeg\"))\n",
        "        \n",
        "        self.total_files = list(zip(self.image_files, self.mask_files))\n",
        "\n",
        "        self.train_transform = A.Compose([A.HorizontalFlip(p=0.5),\n",
        "                                          A.VerticalFlip(p=0.5),\n",
        "                                          A.RandomGamma (gamma_limit=(70, 130), eps=None, always_apply=False, p=0.2),\n",
        "                                          A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n",
        "                                          A.OneOf([A.Blur(), A.GaussianBlur(), A.GlassBlur(), A.MotionBlur(), A.GaussNoise(), A.Sharpen(), A.MedianBlur(), A.MultiplicativeNoise()]),\n",
        "                                          A.Cutout(p=0.2, max_h_size=35, max_w_size=35, fill_value=255),\n",
        "                                          A.RandomSnow(snow_point_lower=0.1, snow_point_upper=0.15, brightness_coeff=1.5, p=0.09),\n",
        "                                          A.RandomShadow(p=0.1),\n",
        "                                          A.ShiftScaleRotate(p=0.45, border_mode=cv2.BORDER_CONSTANT, shift_limit=0.15, scale_limit=0.15),\n",
        "                                          A.RandomCrop(self.img_size, self.img_size)])\n",
        "        \n",
        "        self.batch_transform = A.Compose([A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
        "                                          ToTensorV2()])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.total_files)\n",
        "    \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        prob = random.random()\n",
        "\n",
        "        if prob <= 0.3:\n",
        "            image_path, mask_path = self.total_files[index]\n",
        "            image, mask = load_img_mask(image_path, mask_path, size=self.img_size)\n",
        "\n",
        "            augment_image, augment_mask = train_img_mask_transform(self.train_transform, image, mask)\n",
        "\n",
        "        elif 0.3 < prob <= 0.6:\n",
        "            piecies = []\n",
        "            while len(piecies) < 4:\n",
        "                i = random.randint(0, len(self.total_files)-1)\n",
        "                image_path, mask_path = self.total_files[i]\n",
        "                image, mask = load_img_mask(image_path, mask_path, size=self.img_size)\n",
        "                piece_image, piece_mask = train_img_mask_transform(self.train_transform, image, mask)\n",
        "                piecies.append([piece_image, piece_mask])\n",
        "\n",
        "            augment_image, augment_mask = mosaic_augmentation(piecies, size=self.img_size)\n",
        "\n",
        "\n",
        "        elif 0.6 < prob <= 1:\n",
        "            image_path, mask_path = self.total_files[index]\n",
        "            image, mask = load_img_mask(image_path, mask_path, size=self.img_size)\n",
        "            augment_image, augment_mask = spatially_exclusive_pasting(image, mask, alpha=random.uniform(self.spatial_alpha, self.spatial_alpha + 0.2))\n",
        "\n",
        "        encoded_mask = encode_mask(augment_mask)\n",
        "        batch_image, batch_mask = train_img_mask_transform(self.batch_transform, augment_image, encoded_mask)\n",
        "\n",
        "        return batch_image, batch_mask"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 3,
      "metadata": {
        "id": "ll2YO9_YYHw7"
=======
      "execution_count": 4,
      "metadata": {
        "id": "LC_FKjFpYmkZ"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "/home/pervinco/.local/lib/python3.8/site-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
=======
            "/home/pervinco/anaconda3/envs/openmmlab/lib/python3.10/site-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
<<<<<<< HEAD
        "train_transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.RandomGamma (gamma_limit=(70, 130), eps=None, always_apply=False, p=0.2),\n",
        "    A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n",
        "    A.OneOf([A.Blur(), A.GaussianBlur(), A.GlassBlur(), A.MotionBlur(), A.GaussNoise(), A.Sharpen(), A.MedianBlur(), A.MultiplicativeNoise()]),\n",
        "    A.Cutout(p=0.2, max_h_size=35, max_w_size=35, fill_value=255),\n",
        "    A.RandomSnow(snow_point_lower=0.1, snow_point_upper=0.15, brightness_coeff=1.5, p=0.09),\n",
        "    A.RandomShadow(p=0.1),\n",
        "    A.ShiftScaleRotate(p=0.45, border_mode=cv2.BORDER_CONSTANT, shift_limit=0.15, scale_limit=0.15),\n",
        "    A.RandomCrop(trainsize, trainsize),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LC_FKjFpYmkZ"
      },
      "outputs": [],
      "source": [
        "train_dataset = BKpolypDataset(dir=\"/home/pervinco/Datasets/BKAI_IGH_NeoPolyp\", transform=train_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PcLAkcOFYnpP"
      },
      "outputs": [],
      "source": [
        "class UnNormalize(object):\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
        "        Returns:\n",
        "            Tensor: Normalized image.\n",
        "        \"\"\"\n",
        "        for t, m, s in zip(tensor, self.mean, self.std):\n",
        "            t.mul_(s).add_(m)\n",
        "        return tensor\n",
        "    \n",
        "unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PdQHxvAkYdcF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 2], dtype=torch.uint8)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import random\n",
        "id_test = random.randint(0, train_dataset.__len__())\n",
        "sample1, sample2 = train_dataset.__getitem__(id_test)\n",
        "print(torch.unique(sample2))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(unorm(sample1).permute(1, 2, 0))\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(sample2.squeeze())\n",
        "plt.show()"
=======
        "with open(\"config.yaml\", \"r\") as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "## Device Setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_workers = min([os.cpu_count(), config[\"batch_size\"] if config[\"batch_size\"] > 1 else 0, 8])\n",
        "\n",
        "## Dataset\n",
        "train_dataset = BKAIDataset(config)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=num_workers)"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 7,
=======
      "execution_count": 5,
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
      "metadata": {
        "id": "FW1qSpjgkZw5"
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 8,
=======
      "execution_count": 6,
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
      "metadata": {
        "id": "3YtZ1CpEpIYg"
      },
      "outputs": [],
      "source": [
        "#metrics\n",
        "#tham khao: https://github.com/hszhao/semseg/blob/master/util/util.py\n",
        "def intersectionAndUnionGPU(output, target, K, ignore_index=255):\n",
        "    # 'K' classes, output and target sizes are N or N * L or N * H * W, each value in range 0 to K - 1.\n",
        "    assert (output.dim() in [1, 2, 3])\n",
        "    assert output.shape == target.shape\n",
        "    output = output.view(-1)\n",
        "    target = target.view(-1)\n",
        "    output[target == ignore_index] = ignore_index\n",
        "    intersection = output[output == target]\n",
        "    area_intersection = torch.histc(intersection, bins=K, min=0, max=K-1)\n",
        "    area_output = torch.histc(output, bins=K, min=0, max=K-1)\n",
        "    area_target = torch.histc(target, bins=K, min=0, max=K-1)\n",
        "    area_union = area_output + area_target - area_intersection\n",
        "    return area_intersection, area_union, area_target "
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 9,
=======
      "execution_count": 7,
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
      "metadata": {
        "id": "fbRQ684zvNMV"
      },
      "outputs": [],
      "source": [
        "class FocalLoss_Ori(nn.Module):\n",
<<<<<<< HEAD
        "    \"\"\"\n",
        "    This is a implementation of Focal Loss with smooth label cross entropy supported which is proposed in\n",
        "    'Focal Loss for Dense Object Detection. (https://arxiv.org/abs/1708.02002)'\n",
        "    Focal_Loss= -1*alpha*((1-pt)**gamma)*log(pt)\n",
        "    Args:\n",
        "        num_class: number of classes\n",
        "        alpha: class balance factor\n",
        "        gamma:\n",
        "        ignore_index:\n",
        "        reduction:\n",
        "    \"\"\"\n",
        "\n",
=======
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
        "    def __init__(self, num_class, alpha=None, gamma=2, ignore_index=None, reduction='mean'):\n",
        "        super(FocalLoss_Ori, self).__init__()\n",
        "        self.num_class = num_class\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "        self.smooth = 1e-4\n",
        "        self.ignore_index = ignore_index\n",
        "        self.alpha = alpha\n",
        "        if alpha is None:\n",
        "            self.alpha = torch.ones(num_class, )\n",
        "        elif isinstance(alpha, (int, float)):\n",
        "            self.alpha = torch.as_tensor([alpha] * num_class)\n",
        "        elif isinstance(alpha, (list, np.ndarray)):\n",
        "            self.alpha = torch.as_tensor(alpha)\n",
        "        if self.alpha.shape[0] != num_class:\n",
        "            raise RuntimeError('the length not equal to number of class')\n",
        "\n",
<<<<<<< HEAD
        "        # if isinstance(self.alpha, (list, tuple, np.ndarray)):\n",
        "        #     assert len(self.alpha) == self.num_class\n",
        "        #     self.alpha = torch.Tensor(list(self.alpha))\n",
        "        # elif isinstance(self.alpha, (float, int)):\n",
        "        #     assert 0 < self.alpha < 1.0, 'alpha should be in `(0,1)`)'\n",
        "        #     assert balance_index > -1\n",
        "        #     alpha = torch.ones((self.num_class))\n",
        "        #     alpha *= 1 - self.alpha\n",
        "        #     alpha[balance_index] = self.alpha\n",
        "        #     self.alpha = alpha\n",
        "        # elif isinstance(self.alpha, torch.Tensor):\n",
        "        #     self.alpha = self.alpha\n",
        "        # else:\n",
        "        #     raise TypeError('Not support alpha type, expect `int|float|list|tuple|torch.Tensor`')\n",
        "\n",
        "    def forward(self, logit, target):\n",
        "        # assert isinstance(self.alpha,torch.Tensor)\\\n",
=======
        "    def forward(self, logit, target):\n",
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
        "        N, C = logit.shape[:2]\n",
        "        alpha = self.alpha.to(logit.device)\n",
        "        prob = F.softmax(logit, dim=1)\n",
        "        if prob.dim() > 2:\n",
<<<<<<< HEAD
        "            # N,C,d1,d2 -> N,C,m (m=d1*d2*...)\n",
=======
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
        "            prob = prob.view(N, C, -1)\n",
        "            prob = prob.transpose(1, 2).contiguous()  # [N,C,d1*d2..] -> [N,d1*d2..,C]\n",
        "            prob = prob.view(-1, prob.size(-1))  # [N,d1*d2..,C]-> [N*d1*d2..,C]\n",
        "        ori_shp = target.shape\n",
        "        target = target.view(-1, 1)  # [N,d1,d2,...]->[N*d1*d2*...,1]\n",
<<<<<<< HEAD
=======
        "        \n",
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
        "        valid_mask = None\n",
        "        if self.ignore_index is not None:\n",
        "            valid_mask = target != self.ignore_index\n",
        "            target = target * valid_mask\n",
        "\n",
        "        # ----------memory saving way--------\n",
        "        prob = prob.gather(1, target).view(-1) + self.smooth  # avoid nan\n",
        "        logpt = torch.log(prob)\n",
        "        # alpha_class = alpha.gather(0, target.view(-1))\n",
        "        alpha_class = alpha[target.squeeze().long()]\n",
        "        class_weight = -alpha_class * torch.pow(torch.sub(1.0, prob), self.gamma)\n",
        "        loss = class_weight * logpt\n",
        "        if valid_mask is not None:\n",
        "            loss = loss * valid_mask.squeeze()\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            loss = loss.mean()\n",
        "            if valid_mask is not None:\n",
        "                loss = loss.sum() / valid_mask.sum()\n",
        "        elif self.reduction == 'none':\n",
        "            loss = loss.view(ori_shp)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 10,
=======
      "execution_count": 8,
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
      "metadata": {
        "id": "KyBQfeS9pXni"
      },
      "outputs": [
        {
<<<<<<< HEAD
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_workers = 32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/pervinco/.local/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
            "  warnings.warn(\n",
            "/home/pervinco/.local/lib/python3.8/site-packages/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n",
            "2023-10-07 17:22:43,804 - mmcv - INFO - initialize MixVisionTransformer with init_cfg {'type': 'Pretrained', 'checkpoint': './pretrained_models/mit_b4_mmseg.pth'}\n",
            "2023-10-07 17:22:43,804 - mmcv - INFO - load model from: ./pretrained_models/mit_b4_mmseg.pth\n",
            "2023-10-07 17:22:43,805 - mmcv - INFO - load checkpoint from local path: ./pretrained_models/mit_b4_mmseg.pth\n",
            "2023-10-07 17:22:43,941 - mmcv - INFO - initialize SegformerHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
            "2023-10-07 17:22:43,943 - mmcv - INFO - \n",
            "backbone.layers.0.0.projection.weight - torch.Size([64, 3, 7, 7]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,943 - mmcv - INFO - \n",
            "backbone.layers.0.0.projection.bias - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,943 - mmcv - INFO - \n",
            "backbone.layers.0.0.norm.weight - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,944 - mmcv - INFO - \n",
            "backbone.layers.0.0.norm.bias - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,944 - mmcv - INFO - \n",
            "backbone.layers.0.1.0.norm1.weight - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,944 - mmcv - INFO - \n",
            "backbone.layers.0.1.0.norm1.bias - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,944 - mmcv - INFO - \n",
            "backbone.layers.0.1.0.attn.attn.in_proj_weight - torch.Size([192, 64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,945 - mmcv - INFO - \n",
            "backbone.layers.0.1.0.attn.attn.in_proj_bias - torch.Size([192]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,945 - mmcv - INFO - \n",
            "backbone.layers.0.1.0.attn.attn.out_proj.weight - torch.Size([64, 64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,945 - mmcv - INFO - \n",
            "backbone.layers.0.1.0.attn.attn.out_proj.bias - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,945 - mmcv - INFO - \n",
            "backbone.layers.0.1.0.attn.sr.weight - torch.Size([64, 64, 8, 8]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,946 - mmcv - INFO - \n",
            "backbone.layers.0.1.0.attn.sr.bias - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,946 - mmcv - INFO - \n",
            "backbone.layers.0.1.0.attn.norm.weight - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,946 - mmcv - INFO - \n",
            "backbone.layers.0.1.0.attn.norm.bias - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,946 - mmcv - INFO - \n",
            "backbone.layers.0.1.0.norm2.weight - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,946 - mmcv - INFO - \n",
            "backbone.layers.0.1.0.norm2.bias - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,947 - mmcv - INFO - \n",
            "backbone.layers.0.1.0.ffn.layers.0.weight - torch.Size([256, 64, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,947 - mmcv - INFO - \n",
            "backbone.layers.0.1.0.ffn.layers.0.bias - torch.Size([256]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,947 - mmcv - INFO - \n",
            "backbone.layers.0.1.0.ffn.layers.1.weight - torch.Size([256, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,947 - mmcv - INFO - \n",
            "backbone.layers.0.1.0.ffn.layers.1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,948 - mmcv - INFO - \n",
            "backbone.layers.0.1.0.ffn.layers.4.weight - torch.Size([64, 256, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,948 - mmcv - INFO - \n",
            "backbone.layers.0.1.0.ffn.layers.4.bias - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,948 - mmcv - INFO - \n",
            "backbone.layers.0.1.1.norm1.weight - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,948 - mmcv - INFO - \n",
            "backbone.layers.0.1.1.norm1.bias - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,948 - mmcv - INFO - \n",
            "backbone.layers.0.1.1.attn.attn.in_proj_weight - torch.Size([192, 64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,949 - mmcv - INFO - \n",
            "backbone.layers.0.1.1.attn.attn.in_proj_bias - torch.Size([192]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,949 - mmcv - INFO - \n",
            "backbone.layers.0.1.1.attn.attn.out_proj.weight - torch.Size([64, 64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,949 - mmcv - INFO - \n",
            "backbone.layers.0.1.1.attn.attn.out_proj.bias - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,949 - mmcv - INFO - \n",
            "backbone.layers.0.1.1.attn.sr.weight - torch.Size([64, 64, 8, 8]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,950 - mmcv - INFO - \n",
            "backbone.layers.0.1.1.attn.sr.bias - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,950 - mmcv - INFO - \n",
            "backbone.layers.0.1.1.attn.norm.weight - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,950 - mmcv - INFO - \n",
            "backbone.layers.0.1.1.attn.norm.bias - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,950 - mmcv - INFO - \n",
            "backbone.layers.0.1.1.norm2.weight - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,950 - mmcv - INFO - \n",
            "backbone.layers.0.1.1.norm2.bias - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,950 - mmcv - INFO - \n",
            "backbone.layers.0.1.1.ffn.layers.0.weight - torch.Size([256, 64, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,951 - mmcv - INFO - \n",
            "backbone.layers.0.1.1.ffn.layers.0.bias - torch.Size([256]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,951 - mmcv - INFO - \n",
            "backbone.layers.0.1.1.ffn.layers.1.weight - torch.Size([256, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,951 - mmcv - INFO - \n",
            "backbone.layers.0.1.1.ffn.layers.1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,951 - mmcv - INFO - \n",
            "backbone.layers.0.1.1.ffn.layers.4.weight - torch.Size([64, 256, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,951 - mmcv - INFO - \n",
            "backbone.layers.0.1.1.ffn.layers.4.bias - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,951 - mmcv - INFO - \n",
            "backbone.layers.0.1.2.norm1.weight - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,951 - mmcv - INFO - \n",
            "backbone.layers.0.1.2.norm1.bias - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,951 - mmcv - INFO - \n",
            "backbone.layers.0.1.2.attn.attn.in_proj_weight - torch.Size([192, 64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,951 - mmcv - INFO - \n",
            "backbone.layers.0.1.2.attn.attn.in_proj_bias - torch.Size([192]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,952 - mmcv - INFO - \n",
            "backbone.layers.0.1.2.attn.attn.out_proj.weight - torch.Size([64, 64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,952 - mmcv - INFO - \n",
            "backbone.layers.0.1.2.attn.attn.out_proj.bias - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,952 - mmcv - INFO - \n",
            "backbone.layers.0.1.2.attn.sr.weight - torch.Size([64, 64, 8, 8]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,952 - mmcv - INFO - \n",
            "backbone.layers.0.1.2.attn.sr.bias - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,952 - mmcv - INFO - \n",
            "backbone.layers.0.1.2.attn.norm.weight - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,952 - mmcv - INFO - \n",
            "backbone.layers.0.1.2.attn.norm.bias - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,952 - mmcv - INFO - \n",
            "backbone.layers.0.1.2.norm2.weight - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,952 - mmcv - INFO - \n",
            "backbone.layers.0.1.2.norm2.bias - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,952 - mmcv - INFO - \n",
            "backbone.layers.0.1.2.ffn.layers.0.weight - torch.Size([256, 64, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,953 - mmcv - INFO - \n",
            "backbone.layers.0.1.2.ffn.layers.0.bias - torch.Size([256]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,953 - mmcv - INFO - \n",
            "backbone.layers.0.1.2.ffn.layers.1.weight - torch.Size([256, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,953 - mmcv - INFO - \n",
            "backbone.layers.0.1.2.ffn.layers.1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,953 - mmcv - INFO - \n",
            "backbone.layers.0.1.2.ffn.layers.4.weight - torch.Size([64, 256, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,953 - mmcv - INFO - \n",
            "backbone.layers.0.1.2.ffn.layers.4.bias - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,953 - mmcv - INFO - \n",
            "backbone.layers.0.2.weight - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,953 - mmcv - INFO - \n",
            "backbone.layers.0.2.bias - torch.Size([64]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,953 - mmcv - INFO - \n",
            "backbone.layers.1.0.projection.weight - torch.Size([128, 64, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,953 - mmcv - INFO - \n",
            "backbone.layers.1.0.projection.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,954 - mmcv - INFO - \n",
            "backbone.layers.1.0.norm.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,954 - mmcv - INFO - \n",
            "backbone.layers.1.0.norm.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,954 - mmcv - INFO - \n",
            "backbone.layers.1.1.0.norm1.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,954 - mmcv - INFO - \n",
            "backbone.layers.1.1.0.norm1.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,954 - mmcv - INFO - \n",
            "backbone.layers.1.1.0.attn.attn.in_proj_weight - torch.Size([384, 128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,954 - mmcv - INFO - \n",
            "backbone.layers.1.1.0.attn.attn.in_proj_bias - torch.Size([384]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,954 - mmcv - INFO - \n",
            "backbone.layers.1.1.0.attn.attn.out_proj.weight - torch.Size([128, 128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,954 - mmcv - INFO - \n",
            "backbone.layers.1.1.0.attn.attn.out_proj.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,954 - mmcv - INFO - \n",
            "backbone.layers.1.1.0.attn.sr.weight - torch.Size([128, 128, 4, 4]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,955 - mmcv - INFO - \n",
            "backbone.layers.1.1.0.attn.sr.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,955 - mmcv - INFO - \n",
            "backbone.layers.1.1.0.attn.norm.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,955 - mmcv - INFO - \n",
            "backbone.layers.1.1.0.attn.norm.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,955 - mmcv - INFO - \n",
            "backbone.layers.1.1.0.norm2.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,955 - mmcv - INFO - \n",
            "backbone.layers.1.1.0.norm2.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,955 - mmcv - INFO - \n",
            "backbone.layers.1.1.0.ffn.layers.0.weight - torch.Size([512, 128, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,955 - mmcv - INFO - \n",
            "backbone.layers.1.1.0.ffn.layers.0.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,955 - mmcv - INFO - \n",
            "backbone.layers.1.1.0.ffn.layers.1.weight - torch.Size([512, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,955 - mmcv - INFO - \n",
            "backbone.layers.1.1.0.ffn.layers.1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,956 - mmcv - INFO - \n",
            "backbone.layers.1.1.0.ffn.layers.4.weight - torch.Size([128, 512, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,956 - mmcv - INFO - \n",
            "backbone.layers.1.1.0.ffn.layers.4.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,956 - mmcv - INFO - \n",
            "backbone.layers.1.1.1.norm1.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,956 - mmcv - INFO - \n",
            "backbone.layers.1.1.1.norm1.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,956 - mmcv - INFO - \n",
            "backbone.layers.1.1.1.attn.attn.in_proj_weight - torch.Size([384, 128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,956 - mmcv - INFO - \n",
            "backbone.layers.1.1.1.attn.attn.in_proj_bias - torch.Size([384]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,956 - mmcv - INFO - \n",
            "backbone.layers.1.1.1.attn.attn.out_proj.weight - torch.Size([128, 128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,956 - mmcv - INFO - \n",
            "backbone.layers.1.1.1.attn.attn.out_proj.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,956 - mmcv - INFO - \n",
            "backbone.layers.1.1.1.attn.sr.weight - torch.Size([128, 128, 4, 4]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,957 - mmcv - INFO - \n",
            "backbone.layers.1.1.1.attn.sr.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,957 - mmcv - INFO - \n",
            "backbone.layers.1.1.1.attn.norm.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,957 - mmcv - INFO - \n",
            "backbone.layers.1.1.1.attn.norm.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,957 - mmcv - INFO - \n",
            "backbone.layers.1.1.1.norm2.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,957 - mmcv - INFO - \n",
            "backbone.layers.1.1.1.norm2.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,957 - mmcv - INFO - \n",
            "backbone.layers.1.1.1.ffn.layers.0.weight - torch.Size([512, 128, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,957 - mmcv - INFO - \n",
            "backbone.layers.1.1.1.ffn.layers.0.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,957 - mmcv - INFO - \n",
            "backbone.layers.1.1.1.ffn.layers.1.weight - torch.Size([512, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,957 - mmcv - INFO - \n",
            "backbone.layers.1.1.1.ffn.layers.1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,957 - mmcv - INFO - \n",
            "backbone.layers.1.1.1.ffn.layers.4.weight - torch.Size([128, 512, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,958 - mmcv - INFO - \n",
            "backbone.layers.1.1.1.ffn.layers.4.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,958 - mmcv - INFO - \n",
            "backbone.layers.1.1.2.norm1.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,958 - mmcv - INFO - \n",
            "backbone.layers.1.1.2.norm1.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,958 - mmcv - INFO - \n",
            "backbone.layers.1.1.2.attn.attn.in_proj_weight - torch.Size([384, 128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,958 - mmcv - INFO - \n",
            "backbone.layers.1.1.2.attn.attn.in_proj_bias - torch.Size([384]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,958 - mmcv - INFO - \n",
            "backbone.layers.1.1.2.attn.attn.out_proj.weight - torch.Size([128, 128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,958 - mmcv - INFO - \n",
            "backbone.layers.1.1.2.attn.attn.out_proj.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,958 - mmcv - INFO - \n",
            "backbone.layers.1.1.2.attn.sr.weight - torch.Size([128, 128, 4, 4]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,958 - mmcv - INFO - \n",
            "backbone.layers.1.1.2.attn.sr.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,959 - mmcv - INFO - \n",
            "backbone.layers.1.1.2.attn.norm.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,959 - mmcv - INFO - \n",
            "backbone.layers.1.1.2.attn.norm.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,959 - mmcv - INFO - \n",
            "backbone.layers.1.1.2.norm2.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,959 - mmcv - INFO - \n",
            "backbone.layers.1.1.2.norm2.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,959 - mmcv - INFO - \n",
            "backbone.layers.1.1.2.ffn.layers.0.weight - torch.Size([512, 128, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,959 - mmcv - INFO - \n",
            "backbone.layers.1.1.2.ffn.layers.0.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,959 - mmcv - INFO - \n",
            "backbone.layers.1.1.2.ffn.layers.1.weight - torch.Size([512, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,959 - mmcv - INFO - \n",
            "backbone.layers.1.1.2.ffn.layers.1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,959 - mmcv - INFO - \n",
            "backbone.layers.1.1.2.ffn.layers.4.weight - torch.Size([128, 512, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,960 - mmcv - INFO - \n",
            "backbone.layers.1.1.2.ffn.layers.4.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,960 - mmcv - INFO - \n",
            "backbone.layers.1.1.3.norm1.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,960 - mmcv - INFO - \n",
            "backbone.layers.1.1.3.norm1.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,960 - mmcv - INFO - \n",
            "backbone.layers.1.1.3.attn.attn.in_proj_weight - torch.Size([384, 128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,960 - mmcv - INFO - \n",
            "backbone.layers.1.1.3.attn.attn.in_proj_bias - torch.Size([384]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,960 - mmcv - INFO - \n",
            "backbone.layers.1.1.3.attn.attn.out_proj.weight - torch.Size([128, 128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,960 - mmcv - INFO - \n",
            "backbone.layers.1.1.3.attn.attn.out_proj.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,960 - mmcv - INFO - \n",
            "backbone.layers.1.1.3.attn.sr.weight - torch.Size([128, 128, 4, 4]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,961 - mmcv - INFO - \n",
            "backbone.layers.1.1.3.attn.sr.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,961 - mmcv - INFO - \n",
            "backbone.layers.1.1.3.attn.norm.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,961 - mmcv - INFO - \n",
            "backbone.layers.1.1.3.attn.norm.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,961 - mmcv - INFO - \n",
            "backbone.layers.1.1.3.norm2.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,961 - mmcv - INFO - \n",
            "backbone.layers.1.1.3.norm2.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,961 - mmcv - INFO - \n",
            "backbone.layers.1.1.3.ffn.layers.0.weight - torch.Size([512, 128, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,961 - mmcv - INFO - \n",
            "backbone.layers.1.1.3.ffn.layers.0.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,961 - mmcv - INFO - \n",
            "backbone.layers.1.1.3.ffn.layers.1.weight - torch.Size([512, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,961 - mmcv - INFO - \n",
            "backbone.layers.1.1.3.ffn.layers.1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,962 - mmcv - INFO - \n",
            "backbone.layers.1.1.3.ffn.layers.4.weight - torch.Size([128, 512, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,962 - mmcv - INFO - \n",
            "backbone.layers.1.1.3.ffn.layers.4.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,962 - mmcv - INFO - \n",
            "backbone.layers.1.1.4.norm1.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,962 - mmcv - INFO - \n",
            "backbone.layers.1.1.4.norm1.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,962 - mmcv - INFO - \n",
            "backbone.layers.1.1.4.attn.attn.in_proj_weight - torch.Size([384, 128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,962 - mmcv - INFO - \n",
            "backbone.layers.1.1.4.attn.attn.in_proj_bias - torch.Size([384]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,962 - mmcv - INFO - \n",
            "backbone.layers.1.1.4.attn.attn.out_proj.weight - torch.Size([128, 128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,962 - mmcv - INFO - \n",
            "backbone.layers.1.1.4.attn.attn.out_proj.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,962 - mmcv - INFO - \n",
            "backbone.layers.1.1.4.attn.sr.weight - torch.Size([128, 128, 4, 4]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,963 - mmcv - INFO - \n",
            "backbone.layers.1.1.4.attn.sr.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,963 - mmcv - INFO - \n",
            "backbone.layers.1.1.4.attn.norm.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,963 - mmcv - INFO - \n",
            "backbone.layers.1.1.4.attn.norm.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,963 - mmcv - INFO - \n",
            "backbone.layers.1.1.4.norm2.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,963 - mmcv - INFO - \n",
            "backbone.layers.1.1.4.norm2.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,963 - mmcv - INFO - \n",
            "backbone.layers.1.1.4.ffn.layers.0.weight - torch.Size([512, 128, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,963 - mmcv - INFO - \n",
            "backbone.layers.1.1.4.ffn.layers.0.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,963 - mmcv - INFO - \n",
            "backbone.layers.1.1.4.ffn.layers.1.weight - torch.Size([512, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,966 - mmcv - INFO - \n",
            "backbone.layers.1.1.4.ffn.layers.1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,967 - mmcv - INFO - \n",
            "backbone.layers.1.1.4.ffn.layers.4.weight - torch.Size([128, 512, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,967 - mmcv - INFO - \n",
            "backbone.layers.1.1.4.ffn.layers.4.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,967 - mmcv - INFO - \n",
            "backbone.layers.1.1.5.norm1.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,967 - mmcv - INFO - \n",
            "backbone.layers.1.1.5.norm1.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,967 - mmcv - INFO - \n",
            "backbone.layers.1.1.5.attn.attn.in_proj_weight - torch.Size([384, 128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,967 - mmcv - INFO - \n",
            "backbone.layers.1.1.5.attn.attn.in_proj_bias - torch.Size([384]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,967 - mmcv - INFO - \n",
            "backbone.layers.1.1.5.attn.attn.out_proj.weight - torch.Size([128, 128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,967 - mmcv - INFO - \n",
            "backbone.layers.1.1.5.attn.attn.out_proj.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,968 - mmcv - INFO - \n",
            "backbone.layers.1.1.5.attn.sr.weight - torch.Size([128, 128, 4, 4]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,968 - mmcv - INFO - \n",
            "backbone.layers.1.1.5.attn.sr.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,968 - mmcv - INFO - \n",
            "backbone.layers.1.1.5.attn.norm.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,968 - mmcv - INFO - \n",
            "backbone.layers.1.1.5.attn.norm.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,968 - mmcv - INFO - \n",
            "backbone.layers.1.1.5.norm2.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,968 - mmcv - INFO - \n",
            "backbone.layers.1.1.5.norm2.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,968 - mmcv - INFO - \n",
            "backbone.layers.1.1.5.ffn.layers.0.weight - torch.Size([512, 128, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,968 - mmcv - INFO - \n",
            "backbone.layers.1.1.5.ffn.layers.0.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,968 - mmcv - INFO - \n",
            "backbone.layers.1.1.5.ffn.layers.1.weight - torch.Size([512, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,969 - mmcv - INFO - \n",
            "backbone.layers.1.1.5.ffn.layers.1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,969 - mmcv - INFO - \n",
            "backbone.layers.1.1.5.ffn.layers.4.weight - torch.Size([128, 512, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,969 - mmcv - INFO - \n",
            "backbone.layers.1.1.5.ffn.layers.4.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,969 - mmcv - INFO - \n",
            "backbone.layers.1.1.6.norm1.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,969 - mmcv - INFO - \n",
            "backbone.layers.1.1.6.norm1.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,969 - mmcv - INFO - \n",
            "backbone.layers.1.1.6.attn.attn.in_proj_weight - torch.Size([384, 128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,969 - mmcv - INFO - \n",
            "backbone.layers.1.1.6.attn.attn.in_proj_bias - torch.Size([384]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,969 - mmcv - INFO - \n",
            "backbone.layers.1.1.6.attn.attn.out_proj.weight - torch.Size([128, 128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,969 - mmcv - INFO - \n",
            "backbone.layers.1.1.6.attn.attn.out_proj.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,970 - mmcv - INFO - \n",
            "backbone.layers.1.1.6.attn.sr.weight - torch.Size([128, 128, 4, 4]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,970 - mmcv - INFO - \n",
            "backbone.layers.1.1.6.attn.sr.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,970 - mmcv - INFO - \n",
            "backbone.layers.1.1.6.attn.norm.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,970 - mmcv - INFO - \n",
            "backbone.layers.1.1.6.attn.norm.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,970 - mmcv - INFO - \n",
            "backbone.layers.1.1.6.norm2.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,970 - mmcv - INFO - \n",
            "backbone.layers.1.1.6.norm2.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,970 - mmcv - INFO - \n",
            "backbone.layers.1.1.6.ffn.layers.0.weight - torch.Size([512, 128, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,970 - mmcv - INFO - \n",
            "backbone.layers.1.1.6.ffn.layers.0.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,970 - mmcv - INFO - \n",
            "backbone.layers.1.1.6.ffn.layers.1.weight - torch.Size([512, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,971 - mmcv - INFO - \n",
            "backbone.layers.1.1.6.ffn.layers.1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,971 - mmcv - INFO - \n",
            "backbone.layers.1.1.6.ffn.layers.4.weight - torch.Size([128, 512, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,971 - mmcv - INFO - \n",
            "backbone.layers.1.1.6.ffn.layers.4.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,971 - mmcv - INFO - \n",
            "backbone.layers.1.1.7.norm1.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,971 - mmcv - INFO - \n",
            "backbone.layers.1.1.7.norm1.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,971 - mmcv - INFO - \n",
            "backbone.layers.1.1.7.attn.attn.in_proj_weight - torch.Size([384, 128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,971 - mmcv - INFO - \n",
            "backbone.layers.1.1.7.attn.attn.in_proj_bias - torch.Size([384]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,971 - mmcv - INFO - \n",
            "backbone.layers.1.1.7.attn.attn.out_proj.weight - torch.Size([128, 128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,971 - mmcv - INFO - \n",
            "backbone.layers.1.1.7.attn.attn.out_proj.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,972 - mmcv - INFO - \n",
            "backbone.layers.1.1.7.attn.sr.weight - torch.Size([128, 128, 4, 4]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,972 - mmcv - INFO - \n",
            "backbone.layers.1.1.7.attn.sr.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,972 - mmcv - INFO - \n",
            "backbone.layers.1.1.7.attn.norm.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,972 - mmcv - INFO - \n",
            "backbone.layers.1.1.7.attn.norm.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,972 - mmcv - INFO - \n",
            "backbone.layers.1.1.7.norm2.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,972 - mmcv - INFO - \n",
            "backbone.layers.1.1.7.norm2.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,972 - mmcv - INFO - \n",
            "backbone.layers.1.1.7.ffn.layers.0.weight - torch.Size([512, 128, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,972 - mmcv - INFO - \n",
            "backbone.layers.1.1.7.ffn.layers.0.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,972 - mmcv - INFO - \n",
            "backbone.layers.1.1.7.ffn.layers.1.weight - torch.Size([512, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,972 - mmcv - INFO - \n",
            "backbone.layers.1.1.7.ffn.layers.1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,973 - mmcv - INFO - \n",
            "backbone.layers.1.1.7.ffn.layers.4.weight - torch.Size([128, 512, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,973 - mmcv - INFO - \n",
            "backbone.layers.1.1.7.ffn.layers.4.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,973 - mmcv - INFO - \n",
            "backbone.layers.1.2.weight - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,973 - mmcv - INFO - \n",
            "backbone.layers.1.2.bias - torch.Size([128]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,973 - mmcv - INFO - \n",
            "backbone.layers.2.0.projection.weight - torch.Size([320, 128, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,973 - mmcv - INFO - \n",
            "backbone.layers.2.0.projection.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,973 - mmcv - INFO - \n",
            "backbone.layers.2.0.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,973 - mmcv - INFO - \n",
            "backbone.layers.2.0.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,973 - mmcv - INFO - \n",
            "backbone.layers.2.1.0.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,974 - mmcv - INFO - \n",
            "backbone.layers.2.1.0.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,974 - mmcv - INFO - \n",
            "backbone.layers.2.1.0.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,974 - mmcv - INFO - \n",
            "backbone.layers.2.1.0.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,974 - mmcv - INFO - \n",
            "backbone.layers.2.1.0.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,974 - mmcv - INFO - \n",
            "backbone.layers.2.1.0.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,974 - mmcv - INFO - \n",
            "backbone.layers.2.1.0.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,974 - mmcv - INFO - \n",
            "backbone.layers.2.1.0.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,974 - mmcv - INFO - \n",
            "backbone.layers.2.1.0.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,974 - mmcv - INFO - \n",
            "backbone.layers.2.1.0.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,975 - mmcv - INFO - \n",
            "backbone.layers.2.1.0.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,975 - mmcv - INFO - \n",
            "backbone.layers.2.1.0.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,975 - mmcv - INFO - \n",
            "backbone.layers.2.1.0.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,975 - mmcv - INFO - \n",
            "backbone.layers.2.1.0.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,975 - mmcv - INFO - \n",
            "backbone.layers.2.1.0.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,975 - mmcv - INFO - \n",
            "backbone.layers.2.1.0.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,975 - mmcv - INFO - \n",
            "backbone.layers.2.1.0.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,975 - mmcv - INFO - \n",
            "backbone.layers.2.1.0.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,975 - mmcv - INFO - \n",
            "backbone.layers.2.1.1.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,976 - mmcv - INFO - \n",
            "backbone.layers.2.1.1.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,976 - mmcv - INFO - \n",
            "backbone.layers.2.1.1.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,976 - mmcv - INFO - \n",
            "backbone.layers.2.1.1.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,976 - mmcv - INFO - \n",
            "backbone.layers.2.1.1.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,976 - mmcv - INFO - \n",
            "backbone.layers.2.1.1.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,976 - mmcv - INFO - \n",
            "backbone.layers.2.1.1.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,976 - mmcv - INFO - \n",
            "backbone.layers.2.1.1.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,976 - mmcv - INFO - \n",
            "backbone.layers.2.1.1.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,976 - mmcv - INFO - \n",
            "backbone.layers.2.1.1.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,977 - mmcv - INFO - \n",
            "backbone.layers.2.1.1.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,977 - mmcv - INFO - \n",
            "backbone.layers.2.1.1.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,977 - mmcv - INFO - \n",
            "backbone.layers.2.1.1.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,977 - mmcv - INFO - \n",
            "backbone.layers.2.1.1.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,977 - mmcv - INFO - \n",
            "backbone.layers.2.1.1.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,977 - mmcv - INFO - \n",
            "backbone.layers.2.1.1.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,977 - mmcv - INFO - \n",
            "backbone.layers.2.1.1.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,977 - mmcv - INFO - \n",
            "backbone.layers.2.1.1.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,977 - mmcv - INFO - \n",
            "backbone.layers.2.1.2.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,978 - mmcv - INFO - \n",
            "backbone.layers.2.1.2.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,978 - mmcv - INFO - \n",
            "backbone.layers.2.1.2.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,978 - mmcv - INFO - \n",
            "backbone.layers.2.1.2.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,978 - mmcv - INFO - \n",
            "backbone.layers.2.1.2.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,978 - mmcv - INFO - \n",
            "backbone.layers.2.1.2.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,978 - mmcv - INFO - \n",
            "backbone.layers.2.1.2.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,978 - mmcv - INFO - \n",
            "backbone.layers.2.1.2.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,978 - mmcv - INFO - \n",
            "backbone.layers.2.1.2.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,978 - mmcv - INFO - \n",
            "backbone.layers.2.1.2.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,979 - mmcv - INFO - \n",
            "backbone.layers.2.1.2.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,979 - mmcv - INFO - \n",
            "backbone.layers.2.1.2.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,979 - mmcv - INFO - \n",
            "backbone.layers.2.1.2.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,979 - mmcv - INFO - \n",
            "backbone.layers.2.1.2.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,979 - mmcv - INFO - \n",
            "backbone.layers.2.1.2.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,979 - mmcv - INFO - \n",
            "backbone.layers.2.1.2.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,979 - mmcv - INFO - \n",
            "backbone.layers.2.1.2.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,979 - mmcv - INFO - \n",
            "backbone.layers.2.1.2.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,979 - mmcv - INFO - \n",
            "backbone.layers.2.1.3.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,980 - mmcv - INFO - \n",
            "backbone.layers.2.1.3.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,980 - mmcv - INFO - \n",
            "backbone.layers.2.1.3.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,980 - mmcv - INFO - \n",
            "backbone.layers.2.1.3.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,980 - mmcv - INFO - \n",
            "backbone.layers.2.1.3.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,980 - mmcv - INFO - \n",
            "backbone.layers.2.1.3.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,980 - mmcv - INFO - \n",
            "backbone.layers.2.1.3.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,980 - mmcv - INFO - \n",
            "backbone.layers.2.1.3.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,980 - mmcv - INFO - \n",
            "backbone.layers.2.1.3.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,980 - mmcv - INFO - \n",
            "backbone.layers.2.1.3.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,981 - mmcv - INFO - \n",
            "backbone.layers.2.1.3.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,981 - mmcv - INFO - \n",
            "backbone.layers.2.1.3.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,981 - mmcv - INFO - \n",
            "backbone.layers.2.1.3.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,981 - mmcv - INFO - \n",
            "backbone.layers.2.1.3.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,981 - mmcv - INFO - \n",
            "backbone.layers.2.1.3.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,981 - mmcv - INFO - \n",
            "backbone.layers.2.1.3.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,981 - mmcv - INFO - \n",
            "backbone.layers.2.1.3.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,981 - mmcv - INFO - \n",
            "backbone.layers.2.1.3.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,981 - mmcv - INFO - \n",
            "backbone.layers.2.1.4.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,982 - mmcv - INFO - \n",
            "backbone.layers.2.1.4.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,982 - mmcv - INFO - \n",
            "backbone.layers.2.1.4.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,982 - mmcv - INFO - \n",
            "backbone.layers.2.1.4.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,982 - mmcv - INFO - \n",
            "backbone.layers.2.1.4.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,982 - mmcv - INFO - \n",
            "backbone.layers.2.1.4.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,982 - mmcv - INFO - \n",
            "backbone.layers.2.1.4.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,982 - mmcv - INFO - \n",
            "backbone.layers.2.1.4.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,982 - mmcv - INFO - \n",
            "backbone.layers.2.1.4.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,982 - mmcv - INFO - \n",
            "backbone.layers.2.1.4.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,983 - mmcv - INFO - \n",
            "backbone.layers.2.1.4.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,983 - mmcv - INFO - \n",
            "backbone.layers.2.1.4.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,983 - mmcv - INFO - \n",
            "backbone.layers.2.1.4.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,983 - mmcv - INFO - \n",
            "backbone.layers.2.1.4.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,983 - mmcv - INFO - \n",
            "backbone.layers.2.1.4.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,983 - mmcv - INFO - \n",
            "backbone.layers.2.1.4.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,983 - mmcv - INFO - \n",
            "backbone.layers.2.1.4.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,983 - mmcv - INFO - \n",
            "backbone.layers.2.1.4.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,983 - mmcv - INFO - \n",
            "backbone.layers.2.1.5.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,983 - mmcv - INFO - \n",
            "backbone.layers.2.1.5.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,984 - mmcv - INFO - \n",
            "backbone.layers.2.1.5.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,984 - mmcv - INFO - \n",
            "backbone.layers.2.1.5.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,984 - mmcv - INFO - \n",
            "backbone.layers.2.1.5.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,984 - mmcv - INFO - \n",
            "backbone.layers.2.1.5.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,984 - mmcv - INFO - \n",
            "backbone.layers.2.1.5.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,984 - mmcv - INFO - \n",
            "backbone.layers.2.1.5.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,984 - mmcv - INFO - \n",
            "backbone.layers.2.1.5.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,984 - mmcv - INFO - \n",
            "backbone.layers.2.1.5.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,984 - mmcv - INFO - \n",
            "backbone.layers.2.1.5.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,985 - mmcv - INFO - \n",
            "backbone.layers.2.1.5.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,985 - mmcv - INFO - \n",
            "backbone.layers.2.1.5.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,985 - mmcv - INFO - \n",
            "backbone.layers.2.1.5.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,985 - mmcv - INFO - \n",
            "backbone.layers.2.1.5.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,985 - mmcv - INFO - \n",
            "backbone.layers.2.1.5.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,985 - mmcv - INFO - \n",
            "backbone.layers.2.1.5.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,985 - mmcv - INFO - \n",
            "backbone.layers.2.1.5.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,985 - mmcv - INFO - \n",
            "backbone.layers.2.1.6.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,985 - mmcv - INFO - \n",
            "backbone.layers.2.1.6.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,986 - mmcv - INFO - \n",
            "backbone.layers.2.1.6.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,986 - mmcv - INFO - \n",
            "backbone.layers.2.1.6.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,986 - mmcv - INFO - \n",
            "backbone.layers.2.1.6.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,986 - mmcv - INFO - \n",
            "backbone.layers.2.1.6.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,986 - mmcv - INFO - \n",
            "backbone.layers.2.1.6.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,986 - mmcv - INFO - \n",
            "backbone.layers.2.1.6.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,986 - mmcv - INFO - \n",
            "backbone.layers.2.1.6.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,986 - mmcv - INFO - \n",
            "backbone.layers.2.1.6.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,986 - mmcv - INFO - \n",
            "backbone.layers.2.1.6.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,987 - mmcv - INFO - \n",
            "backbone.layers.2.1.6.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,987 - mmcv - INFO - \n",
            "backbone.layers.2.1.6.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,987 - mmcv - INFO - \n",
            "backbone.layers.2.1.6.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,987 - mmcv - INFO - \n",
            "backbone.layers.2.1.6.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,987 - mmcv - INFO - \n",
            "backbone.layers.2.1.6.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,987 - mmcv - INFO - \n",
            "backbone.layers.2.1.6.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,987 - mmcv - INFO - \n",
            "backbone.layers.2.1.6.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,987 - mmcv - INFO - \n",
            "backbone.layers.2.1.7.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,987 - mmcv - INFO - \n",
            "backbone.layers.2.1.7.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,988 - mmcv - INFO - \n",
            "backbone.layers.2.1.7.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,988 - mmcv - INFO - \n",
            "backbone.layers.2.1.7.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,988 - mmcv - INFO - \n",
            "backbone.layers.2.1.7.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,988 - mmcv - INFO - \n",
            "backbone.layers.2.1.7.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,988 - mmcv - INFO - \n",
            "backbone.layers.2.1.7.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,988 - mmcv - INFO - \n",
            "backbone.layers.2.1.7.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,988 - mmcv - INFO - \n",
            "backbone.layers.2.1.7.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,988 - mmcv - INFO - \n",
            "backbone.layers.2.1.7.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,988 - mmcv - INFO - \n",
            "backbone.layers.2.1.7.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,989 - mmcv - INFO - \n",
            "backbone.layers.2.1.7.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,989 - mmcv - INFO - \n",
            "backbone.layers.2.1.7.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,989 - mmcv - INFO - \n",
            "backbone.layers.2.1.7.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,989 - mmcv - INFO - \n",
            "backbone.layers.2.1.7.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,989 - mmcv - INFO - \n",
            "backbone.layers.2.1.7.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,989 - mmcv - INFO - \n",
            "backbone.layers.2.1.7.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,989 - mmcv - INFO - \n",
            "backbone.layers.2.1.7.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,989 - mmcv - INFO - \n",
            "backbone.layers.2.1.8.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,990 - mmcv - INFO - \n",
            "backbone.layers.2.1.8.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,990 - mmcv - INFO - \n",
            "backbone.layers.2.1.8.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,990 - mmcv - INFO - \n",
            "backbone.layers.2.1.8.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,990 - mmcv - INFO - \n",
            "backbone.layers.2.1.8.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,990 - mmcv - INFO - \n",
            "backbone.layers.2.1.8.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,990 - mmcv - INFO - \n",
            "backbone.layers.2.1.8.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,990 - mmcv - INFO - \n",
            "backbone.layers.2.1.8.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,990 - mmcv - INFO - \n",
            "backbone.layers.2.1.8.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,990 - mmcv - INFO - \n",
            "backbone.layers.2.1.8.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,991 - mmcv - INFO - \n",
            "backbone.layers.2.1.8.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,991 - mmcv - INFO - \n",
            "backbone.layers.2.1.8.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,991 - mmcv - INFO - \n",
            "backbone.layers.2.1.8.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,991 - mmcv - INFO - \n",
            "backbone.layers.2.1.8.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,991 - mmcv - INFO - \n",
            "backbone.layers.2.1.8.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,991 - mmcv - INFO - \n",
            "backbone.layers.2.1.8.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,991 - mmcv - INFO - \n",
            "backbone.layers.2.1.8.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,991 - mmcv - INFO - \n",
            "backbone.layers.2.1.8.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,991 - mmcv - INFO - \n",
            "backbone.layers.2.1.9.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,992 - mmcv - INFO - \n",
            "backbone.layers.2.1.9.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,992 - mmcv - INFO - \n",
            "backbone.layers.2.1.9.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,992 - mmcv - INFO - \n",
            "backbone.layers.2.1.9.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,992 - mmcv - INFO - \n",
            "backbone.layers.2.1.9.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,992 - mmcv - INFO - \n",
            "backbone.layers.2.1.9.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,992 - mmcv - INFO - \n",
            "backbone.layers.2.1.9.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,992 - mmcv - INFO - \n",
            "backbone.layers.2.1.9.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,992 - mmcv - INFO - \n",
            "backbone.layers.2.1.9.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,992 - mmcv - INFO - \n",
            "backbone.layers.2.1.9.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,993 - mmcv - INFO - \n",
            "backbone.layers.2.1.9.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,993 - mmcv - INFO - \n",
            "backbone.layers.2.1.9.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,993 - mmcv - INFO - \n",
            "backbone.layers.2.1.9.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,993 - mmcv - INFO - \n",
            "backbone.layers.2.1.9.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,993 - mmcv - INFO - \n",
            "backbone.layers.2.1.9.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,993 - mmcv - INFO - \n",
            "backbone.layers.2.1.9.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,993 - mmcv - INFO - \n",
            "backbone.layers.2.1.9.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,993 - mmcv - INFO - \n",
            "backbone.layers.2.1.9.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,993 - mmcv - INFO - \n",
            "backbone.layers.2.1.10.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,993 - mmcv - INFO - \n",
            "backbone.layers.2.1.10.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,994 - mmcv - INFO - \n",
            "backbone.layers.2.1.10.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,994 - mmcv - INFO - \n",
            "backbone.layers.2.1.10.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,994 - mmcv - INFO - \n",
            "backbone.layers.2.1.10.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,994 - mmcv - INFO - \n",
            "backbone.layers.2.1.10.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,994 - mmcv - INFO - \n",
            "backbone.layers.2.1.10.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,994 - mmcv - INFO - \n",
            "backbone.layers.2.1.10.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,994 - mmcv - INFO - \n",
            "backbone.layers.2.1.10.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,994 - mmcv - INFO - \n",
            "backbone.layers.2.1.10.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,994 - mmcv - INFO - \n",
            "backbone.layers.2.1.10.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,995 - mmcv - INFO - \n",
            "backbone.layers.2.1.10.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,995 - mmcv - INFO - \n",
            "backbone.layers.2.1.10.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,995 - mmcv - INFO - \n",
            "backbone.layers.2.1.10.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,995 - mmcv - INFO - \n",
            "backbone.layers.2.1.10.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,995 - mmcv - INFO - \n",
            "backbone.layers.2.1.10.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,995 - mmcv - INFO - \n",
            "backbone.layers.2.1.10.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,995 - mmcv - INFO - \n",
            "backbone.layers.2.1.10.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,995 - mmcv - INFO - \n",
            "backbone.layers.2.1.11.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,995 - mmcv - INFO - \n",
            "backbone.layers.2.1.11.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,996 - mmcv - INFO - \n",
            "backbone.layers.2.1.11.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,996 - mmcv - INFO - \n",
            "backbone.layers.2.1.11.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,996 - mmcv - INFO - \n",
            "backbone.layers.2.1.11.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,996 - mmcv - INFO - \n",
            "backbone.layers.2.1.11.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,996 - mmcv - INFO - \n",
            "backbone.layers.2.1.11.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,996 - mmcv - INFO - \n",
            "backbone.layers.2.1.11.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,996 - mmcv - INFO - \n",
            "backbone.layers.2.1.11.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,996 - mmcv - INFO - \n",
            "backbone.layers.2.1.11.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,996 - mmcv - INFO - \n",
            "backbone.layers.2.1.11.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,997 - mmcv - INFO - \n",
            "backbone.layers.2.1.11.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,997 - mmcv - INFO - \n",
            "backbone.layers.2.1.11.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,997 - mmcv - INFO - \n",
            "backbone.layers.2.1.11.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,997 - mmcv - INFO - \n",
            "backbone.layers.2.1.11.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,997 - mmcv - INFO - \n",
            "backbone.layers.2.1.11.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,997 - mmcv - INFO - \n",
            "backbone.layers.2.1.11.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,997 - mmcv - INFO - \n",
            "backbone.layers.2.1.11.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,997 - mmcv - INFO - \n",
            "backbone.layers.2.1.12.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,997 - mmcv - INFO - \n",
            "backbone.layers.2.1.12.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,997 - mmcv - INFO - \n",
            "backbone.layers.2.1.12.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,998 - mmcv - INFO - \n",
            "backbone.layers.2.1.12.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,998 - mmcv - INFO - \n",
            "backbone.layers.2.1.12.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,998 - mmcv - INFO - \n",
            "backbone.layers.2.1.12.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,998 - mmcv - INFO - \n",
            "backbone.layers.2.1.12.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,998 - mmcv - INFO - \n",
            "backbone.layers.2.1.12.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,998 - mmcv - INFO - \n",
            "backbone.layers.2.1.12.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,998 - mmcv - INFO - \n",
            "backbone.layers.2.1.12.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,998 - mmcv - INFO - \n",
            "backbone.layers.2.1.12.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,998 - mmcv - INFO - \n",
            "backbone.layers.2.1.12.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,999 - mmcv - INFO - \n",
            "backbone.layers.2.1.12.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,999 - mmcv - INFO - \n",
            "backbone.layers.2.1.12.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,999 - mmcv - INFO - \n",
            "backbone.layers.2.1.12.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,999 - mmcv - INFO - \n",
            "backbone.layers.2.1.12.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,999 - mmcv - INFO - \n",
            "backbone.layers.2.1.12.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,999 - mmcv - INFO - \n",
            "backbone.layers.2.1.12.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,999 - mmcv - INFO - \n",
            "backbone.layers.2.1.13.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,999 - mmcv - INFO - \n",
            "backbone.layers.2.1.13.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:43,999 - mmcv - INFO - \n",
            "backbone.layers.2.1.13.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,000 - mmcv - INFO - \n",
            "backbone.layers.2.1.13.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,000 - mmcv - INFO - \n",
            "backbone.layers.2.1.13.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,000 - mmcv - INFO - \n",
            "backbone.layers.2.1.13.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,000 - mmcv - INFO - \n",
            "backbone.layers.2.1.13.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,000 - mmcv - INFO - \n",
            "backbone.layers.2.1.13.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,000 - mmcv - INFO - \n",
            "backbone.layers.2.1.13.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,000 - mmcv - INFO - \n",
            "backbone.layers.2.1.13.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,000 - mmcv - INFO - \n",
            "backbone.layers.2.1.13.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,000 - mmcv - INFO - \n",
            "backbone.layers.2.1.13.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,001 - mmcv - INFO - \n",
            "backbone.layers.2.1.13.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,001 - mmcv - INFO - \n",
            "backbone.layers.2.1.13.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,001 - mmcv - INFO - \n",
            "backbone.layers.2.1.13.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,001 - mmcv - INFO - \n",
            "backbone.layers.2.1.13.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,001 - mmcv - INFO - \n",
            "backbone.layers.2.1.13.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,001 - mmcv - INFO - \n",
            "backbone.layers.2.1.13.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,001 - mmcv - INFO - \n",
            "backbone.layers.2.1.14.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,001 - mmcv - INFO - \n",
            "backbone.layers.2.1.14.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,001 - mmcv - INFO - \n",
            "backbone.layers.2.1.14.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,002 - mmcv - INFO - \n",
            "backbone.layers.2.1.14.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,002 - mmcv - INFO - \n",
            "backbone.layers.2.1.14.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,002 - mmcv - INFO - \n",
            "backbone.layers.2.1.14.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,002 - mmcv - INFO - \n",
            "backbone.layers.2.1.14.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,002 - mmcv - INFO - \n",
            "backbone.layers.2.1.14.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,002 - mmcv - INFO - \n",
            "backbone.layers.2.1.14.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,002 - mmcv - INFO - \n",
            "backbone.layers.2.1.14.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,002 - mmcv - INFO - \n",
            "backbone.layers.2.1.14.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,002 - mmcv - INFO - \n",
            "backbone.layers.2.1.14.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,003 - mmcv - INFO - \n",
            "backbone.layers.2.1.14.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,003 - mmcv - INFO - \n",
            "backbone.layers.2.1.14.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,003 - mmcv - INFO - \n",
            "backbone.layers.2.1.14.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,003 - mmcv - INFO - \n",
            "backbone.layers.2.1.14.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,003 - mmcv - INFO - \n",
            "backbone.layers.2.1.14.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,003 - mmcv - INFO - \n",
            "backbone.layers.2.1.14.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,003 - mmcv - INFO - \n",
            "backbone.layers.2.1.15.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,003 - mmcv - INFO - \n",
            "backbone.layers.2.1.15.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,003 - mmcv - INFO - \n",
            "backbone.layers.2.1.15.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,004 - mmcv - INFO - \n",
            "backbone.layers.2.1.15.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,004 - mmcv - INFO - \n",
            "backbone.layers.2.1.15.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,004 - mmcv - INFO - \n",
            "backbone.layers.2.1.15.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,004 - mmcv - INFO - \n",
            "backbone.layers.2.1.15.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,004 - mmcv - INFO - \n",
            "backbone.layers.2.1.15.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,004 - mmcv - INFO - \n",
            "backbone.layers.2.1.15.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,004 - mmcv - INFO - \n",
            "backbone.layers.2.1.15.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,004 - mmcv - INFO - \n",
            "backbone.layers.2.1.15.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,004 - mmcv - INFO - \n",
            "backbone.layers.2.1.15.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,004 - mmcv - INFO - \n",
            "backbone.layers.2.1.15.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,005 - mmcv - INFO - \n",
            "backbone.layers.2.1.15.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,005 - mmcv - INFO - \n",
            "backbone.layers.2.1.15.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,005 - mmcv - INFO - \n",
            "backbone.layers.2.1.15.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,005 - mmcv - INFO - \n",
            "backbone.layers.2.1.15.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,005 - mmcv - INFO - \n",
            "backbone.layers.2.1.15.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,005 - mmcv - INFO - \n",
            "backbone.layers.2.1.16.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,005 - mmcv - INFO - \n",
            "backbone.layers.2.1.16.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,005 - mmcv - INFO - \n",
            "backbone.layers.2.1.16.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,005 - mmcv - INFO - \n",
            "backbone.layers.2.1.16.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,006 - mmcv - INFO - \n",
            "backbone.layers.2.1.16.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,006 - mmcv - INFO - \n",
            "backbone.layers.2.1.16.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,006 - mmcv - INFO - \n",
            "backbone.layers.2.1.16.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,006 - mmcv - INFO - \n",
            "backbone.layers.2.1.16.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,006 - mmcv - INFO - \n",
            "backbone.layers.2.1.16.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,006 - mmcv - INFO - \n",
            "backbone.layers.2.1.16.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,006 - mmcv - INFO - \n",
            "backbone.layers.2.1.16.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,006 - mmcv - INFO - \n",
            "backbone.layers.2.1.16.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,006 - mmcv - INFO - \n",
            "backbone.layers.2.1.16.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,007 - mmcv - INFO - \n",
            "backbone.layers.2.1.16.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,007 - mmcv - INFO - \n",
            "backbone.layers.2.1.16.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,007 - mmcv - INFO - \n",
            "backbone.layers.2.1.16.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,007 - mmcv - INFO - \n",
            "backbone.layers.2.1.16.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,007 - mmcv - INFO - \n",
            "backbone.layers.2.1.16.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,007 - mmcv - INFO - \n",
            "backbone.layers.2.1.17.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,007 - mmcv - INFO - \n",
            "backbone.layers.2.1.17.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,007 - mmcv - INFO - \n",
            "backbone.layers.2.1.17.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,007 - mmcv - INFO - \n",
            "backbone.layers.2.1.17.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,008 - mmcv - INFO - \n",
            "backbone.layers.2.1.17.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,008 - mmcv - INFO - \n",
            "backbone.layers.2.1.17.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,008 - mmcv - INFO - \n",
            "backbone.layers.2.1.17.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,008 - mmcv - INFO - \n",
            "backbone.layers.2.1.17.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,008 - mmcv - INFO - \n",
            "backbone.layers.2.1.17.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,008 - mmcv - INFO - \n",
            "backbone.layers.2.1.17.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,008 - mmcv - INFO - \n",
            "backbone.layers.2.1.17.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,008 - mmcv - INFO - \n",
            "backbone.layers.2.1.17.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,008 - mmcv - INFO - \n",
            "backbone.layers.2.1.17.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,009 - mmcv - INFO - \n",
            "backbone.layers.2.1.17.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,009 - mmcv - INFO - \n",
            "backbone.layers.2.1.17.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,009 - mmcv - INFO - \n",
            "backbone.layers.2.1.17.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,009 - mmcv - INFO - \n",
            "backbone.layers.2.1.17.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,009 - mmcv - INFO - \n",
            "backbone.layers.2.1.17.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,009 - mmcv - INFO - \n",
            "backbone.layers.2.1.18.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,009 - mmcv - INFO - \n",
            "backbone.layers.2.1.18.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,009 - mmcv - INFO - \n",
            "backbone.layers.2.1.18.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,009 - mmcv - INFO - \n",
            "backbone.layers.2.1.18.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,009 - mmcv - INFO - \n",
            "backbone.layers.2.1.18.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,010 - mmcv - INFO - \n",
            "backbone.layers.2.1.18.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,010 - mmcv - INFO - \n",
            "backbone.layers.2.1.18.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,010 - mmcv - INFO - \n",
            "backbone.layers.2.1.18.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,010 - mmcv - INFO - \n",
            "backbone.layers.2.1.18.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,010 - mmcv - INFO - \n",
            "backbone.layers.2.1.18.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,010 - mmcv - INFO - \n",
            "backbone.layers.2.1.18.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,010 - mmcv - INFO - \n",
            "backbone.layers.2.1.18.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,010 - mmcv - INFO - \n",
            "backbone.layers.2.1.18.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,010 - mmcv - INFO - \n",
            "backbone.layers.2.1.18.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,011 - mmcv - INFO - \n",
            "backbone.layers.2.1.18.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,011 - mmcv - INFO - \n",
            "backbone.layers.2.1.18.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,011 - mmcv - INFO - \n",
            "backbone.layers.2.1.18.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,011 - mmcv - INFO - \n",
            "backbone.layers.2.1.18.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,011 - mmcv - INFO - \n",
            "backbone.layers.2.1.19.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,011 - mmcv - INFO - \n",
            "backbone.layers.2.1.19.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,011 - mmcv - INFO - \n",
            "backbone.layers.2.1.19.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,011 - mmcv - INFO - \n",
            "backbone.layers.2.1.19.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,011 - mmcv - INFO - \n",
            "backbone.layers.2.1.19.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,012 - mmcv - INFO - \n",
            "backbone.layers.2.1.19.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,012 - mmcv - INFO - \n",
            "backbone.layers.2.1.19.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,012 - mmcv - INFO - \n",
            "backbone.layers.2.1.19.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,012 - mmcv - INFO - \n",
            "backbone.layers.2.1.19.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,012 - mmcv - INFO - \n",
            "backbone.layers.2.1.19.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,012 - mmcv - INFO - \n",
            "backbone.layers.2.1.19.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,012 - mmcv - INFO - \n",
            "backbone.layers.2.1.19.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,012 - mmcv - INFO - \n",
            "backbone.layers.2.1.19.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,012 - mmcv - INFO - \n",
            "backbone.layers.2.1.19.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,013 - mmcv - INFO - \n",
            "backbone.layers.2.1.19.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,013 - mmcv - INFO - \n",
            "backbone.layers.2.1.19.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,013 - mmcv - INFO - \n",
            "backbone.layers.2.1.19.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,013 - mmcv - INFO - \n",
            "backbone.layers.2.1.19.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,013 - mmcv - INFO - \n",
            "backbone.layers.2.1.20.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,013 - mmcv - INFO - \n",
            "backbone.layers.2.1.20.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,013 - mmcv - INFO - \n",
            "backbone.layers.2.1.20.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,013 - mmcv - INFO - \n",
            "backbone.layers.2.1.20.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,013 - mmcv - INFO - \n",
            "backbone.layers.2.1.20.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,014 - mmcv - INFO - \n",
            "backbone.layers.2.1.20.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,014 - mmcv - INFO - \n",
            "backbone.layers.2.1.20.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,014 - mmcv - INFO - \n",
            "backbone.layers.2.1.20.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,014 - mmcv - INFO - \n",
            "backbone.layers.2.1.20.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,014 - mmcv - INFO - \n",
            "backbone.layers.2.1.20.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,014 - mmcv - INFO - \n",
            "backbone.layers.2.1.20.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,014 - mmcv - INFO - \n",
            "backbone.layers.2.1.20.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,014 - mmcv - INFO - \n",
            "backbone.layers.2.1.20.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,014 - mmcv - INFO - \n",
            "backbone.layers.2.1.20.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,015 - mmcv - INFO - \n",
            "backbone.layers.2.1.20.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,015 - mmcv - INFO - \n",
            "backbone.layers.2.1.20.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,015 - mmcv - INFO - \n",
            "backbone.layers.2.1.20.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,015 - mmcv - INFO - \n",
            "backbone.layers.2.1.20.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,015 - mmcv - INFO - \n",
            "backbone.layers.2.1.21.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,015 - mmcv - INFO - \n",
            "backbone.layers.2.1.21.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,015 - mmcv - INFO - \n",
            "backbone.layers.2.1.21.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,015 - mmcv - INFO - \n",
            "backbone.layers.2.1.21.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,015 - mmcv - INFO - \n",
            "backbone.layers.2.1.21.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,016 - mmcv - INFO - \n",
            "backbone.layers.2.1.21.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,016 - mmcv - INFO - \n",
            "backbone.layers.2.1.21.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,016 - mmcv - INFO - \n",
            "backbone.layers.2.1.21.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,016 - mmcv - INFO - \n",
            "backbone.layers.2.1.21.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,016 - mmcv - INFO - \n",
            "backbone.layers.2.1.21.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,016 - mmcv - INFO - \n",
            "backbone.layers.2.1.21.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,016 - mmcv - INFO - \n",
            "backbone.layers.2.1.21.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,016 - mmcv - INFO - \n",
            "backbone.layers.2.1.21.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,016 - mmcv - INFO - \n",
            "backbone.layers.2.1.21.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,017 - mmcv - INFO - \n",
            "backbone.layers.2.1.21.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,017 - mmcv - INFO - \n",
            "backbone.layers.2.1.21.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,017 - mmcv - INFO - \n",
            "backbone.layers.2.1.21.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,017 - mmcv - INFO - \n",
            "backbone.layers.2.1.21.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,017 - mmcv - INFO - \n",
            "backbone.layers.2.1.22.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,017 - mmcv - INFO - \n",
            "backbone.layers.2.1.22.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,017 - mmcv - INFO - \n",
            "backbone.layers.2.1.22.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,017 - mmcv - INFO - \n",
            "backbone.layers.2.1.22.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,017 - mmcv - INFO - \n",
            "backbone.layers.2.1.22.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,017 - mmcv - INFO - \n",
            "backbone.layers.2.1.22.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,018 - mmcv - INFO - \n",
            "backbone.layers.2.1.22.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,018 - mmcv - INFO - \n",
            "backbone.layers.2.1.22.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,018 - mmcv - INFO - \n",
            "backbone.layers.2.1.22.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,018 - mmcv - INFO - \n",
            "backbone.layers.2.1.22.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,018 - mmcv - INFO - \n",
            "backbone.layers.2.1.22.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,018 - mmcv - INFO - \n",
            "backbone.layers.2.1.22.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,018 - mmcv - INFO - \n",
            "backbone.layers.2.1.22.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,018 - mmcv - INFO - \n",
            "backbone.layers.2.1.22.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,018 - mmcv - INFO - \n",
            "backbone.layers.2.1.22.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,019 - mmcv - INFO - \n",
            "backbone.layers.2.1.22.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,019 - mmcv - INFO - \n",
            "backbone.layers.2.1.22.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,019 - mmcv - INFO - \n",
            "backbone.layers.2.1.22.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,019 - mmcv - INFO - \n",
            "backbone.layers.2.1.23.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,019 - mmcv - INFO - \n",
            "backbone.layers.2.1.23.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,019 - mmcv - INFO - \n",
            "backbone.layers.2.1.23.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,019 - mmcv - INFO - \n",
            "backbone.layers.2.1.23.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,019 - mmcv - INFO - \n",
            "backbone.layers.2.1.23.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,019 - mmcv - INFO - \n",
            "backbone.layers.2.1.23.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,020 - mmcv - INFO - \n",
            "backbone.layers.2.1.23.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,020 - mmcv - INFO - \n",
            "backbone.layers.2.1.23.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,020 - mmcv - INFO - \n",
            "backbone.layers.2.1.23.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,020 - mmcv - INFO - \n",
            "backbone.layers.2.1.23.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,020 - mmcv - INFO - \n",
            "backbone.layers.2.1.23.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,020 - mmcv - INFO - \n",
            "backbone.layers.2.1.23.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,020 - mmcv - INFO - \n",
            "backbone.layers.2.1.23.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,020 - mmcv - INFO - \n",
            "backbone.layers.2.1.23.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,020 - mmcv - INFO - \n",
            "backbone.layers.2.1.23.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,021 - mmcv - INFO - \n",
            "backbone.layers.2.1.23.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,021 - mmcv - INFO - \n",
            "backbone.layers.2.1.23.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,021 - mmcv - INFO - \n",
            "backbone.layers.2.1.23.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,021 - mmcv - INFO - \n",
            "backbone.layers.2.1.24.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,021 - mmcv - INFO - \n",
            "backbone.layers.2.1.24.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,021 - mmcv - INFO - \n",
            "backbone.layers.2.1.24.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,021 - mmcv - INFO - \n",
            "backbone.layers.2.1.24.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,021 - mmcv - INFO - \n",
            "backbone.layers.2.1.24.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,021 - mmcv - INFO - \n",
            "backbone.layers.2.1.24.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,021 - mmcv - INFO - \n",
            "backbone.layers.2.1.24.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,022 - mmcv - INFO - \n",
            "backbone.layers.2.1.24.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,022 - mmcv - INFO - \n",
            "backbone.layers.2.1.24.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,022 - mmcv - INFO - \n",
            "backbone.layers.2.1.24.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,022 - mmcv - INFO - \n",
            "backbone.layers.2.1.24.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,022 - mmcv - INFO - \n",
            "backbone.layers.2.1.24.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,022 - mmcv - INFO - \n",
            "backbone.layers.2.1.24.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,022 - mmcv - INFO - \n",
            "backbone.layers.2.1.24.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,022 - mmcv - INFO - \n",
            "backbone.layers.2.1.24.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,022 - mmcv - INFO - \n",
            "backbone.layers.2.1.24.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,023 - mmcv - INFO - \n",
            "backbone.layers.2.1.24.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,023 - mmcv - INFO - \n",
            "backbone.layers.2.1.24.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,023 - mmcv - INFO - \n",
            "backbone.layers.2.1.25.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,023 - mmcv - INFO - \n",
            "backbone.layers.2.1.25.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,023 - mmcv - INFO - \n",
            "backbone.layers.2.1.25.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,023 - mmcv - INFO - \n",
            "backbone.layers.2.1.25.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,023 - mmcv - INFO - \n",
            "backbone.layers.2.1.25.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,023 - mmcv - INFO - \n",
            "backbone.layers.2.1.25.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,023 - mmcv - INFO - \n",
            "backbone.layers.2.1.25.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,024 - mmcv - INFO - \n",
            "backbone.layers.2.1.25.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,024 - mmcv - INFO - \n",
            "backbone.layers.2.1.25.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,024 - mmcv - INFO - \n",
            "backbone.layers.2.1.25.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,024 - mmcv - INFO - \n",
            "backbone.layers.2.1.25.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,024 - mmcv - INFO - \n",
            "backbone.layers.2.1.25.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,024 - mmcv - INFO - \n",
            "backbone.layers.2.1.25.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,024 - mmcv - INFO - \n",
            "backbone.layers.2.1.25.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,024 - mmcv - INFO - \n",
            "backbone.layers.2.1.25.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,024 - mmcv - INFO - \n",
            "backbone.layers.2.1.25.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,024 - mmcv - INFO - \n",
            "backbone.layers.2.1.25.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,025 - mmcv - INFO - \n",
            "backbone.layers.2.1.25.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,025 - mmcv - INFO - \n",
            "backbone.layers.2.1.26.norm1.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,025 - mmcv - INFO - \n",
            "backbone.layers.2.1.26.norm1.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,025 - mmcv - INFO - \n",
            "backbone.layers.2.1.26.attn.attn.in_proj_weight - torch.Size([960, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,025 - mmcv - INFO - \n",
            "backbone.layers.2.1.26.attn.attn.in_proj_bias - torch.Size([960]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,025 - mmcv - INFO - \n",
            "backbone.layers.2.1.26.attn.attn.out_proj.weight - torch.Size([320, 320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,025 - mmcv - INFO - \n",
            "backbone.layers.2.1.26.attn.attn.out_proj.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,025 - mmcv - INFO - \n",
            "backbone.layers.2.1.26.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,025 - mmcv - INFO - \n",
            "backbone.layers.2.1.26.attn.sr.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,026 - mmcv - INFO - \n",
            "backbone.layers.2.1.26.attn.norm.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,026 - mmcv - INFO - \n",
            "backbone.layers.2.1.26.attn.norm.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,026 - mmcv - INFO - \n",
            "backbone.layers.2.1.26.norm2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,026 - mmcv - INFO - \n",
            "backbone.layers.2.1.26.norm2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,026 - mmcv - INFO - \n",
            "backbone.layers.2.1.26.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,026 - mmcv - INFO - \n",
            "backbone.layers.2.1.26.ffn.layers.0.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,026 - mmcv - INFO - \n",
            "backbone.layers.2.1.26.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,026 - mmcv - INFO - \n",
            "backbone.layers.2.1.26.ffn.layers.1.bias - torch.Size([1280]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,026 - mmcv - INFO - \n",
            "backbone.layers.2.1.26.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,027 - mmcv - INFO - \n",
            "backbone.layers.2.1.26.ffn.layers.4.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,027 - mmcv - INFO - \n",
            "backbone.layers.2.2.weight - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,027 - mmcv - INFO - \n",
            "backbone.layers.2.2.bias - torch.Size([320]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,027 - mmcv - INFO - \n",
            "backbone.layers.3.0.projection.weight - torch.Size([512, 320, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,027 - mmcv - INFO - \n",
            "backbone.layers.3.0.projection.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,027 - mmcv - INFO - \n",
            "backbone.layers.3.0.norm.weight - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,027 - mmcv - INFO - \n",
            "backbone.layers.3.0.norm.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,027 - mmcv - INFO - \n",
            "backbone.layers.3.1.0.norm1.weight - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,027 - mmcv - INFO - \n",
            "backbone.layers.3.1.0.norm1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,028 - mmcv - INFO - \n",
            "backbone.layers.3.1.0.attn.attn.in_proj_weight - torch.Size([1536, 512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,028 - mmcv - INFO - \n",
            "backbone.layers.3.1.0.attn.attn.in_proj_bias - torch.Size([1536]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,028 - mmcv - INFO - \n",
            "backbone.layers.3.1.0.attn.attn.out_proj.weight - torch.Size([512, 512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,028 - mmcv - INFO - \n",
            "backbone.layers.3.1.0.attn.attn.out_proj.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,028 - mmcv - INFO - \n",
            "backbone.layers.3.1.0.norm2.weight - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,028 - mmcv - INFO - \n",
            "backbone.layers.3.1.0.norm2.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,028 - mmcv - INFO - \n",
            "backbone.layers.3.1.0.ffn.layers.0.weight - torch.Size([2048, 512, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,028 - mmcv - INFO - \n",
            "backbone.layers.3.1.0.ffn.layers.0.bias - torch.Size([2048]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,028 - mmcv - INFO - \n",
            "backbone.layers.3.1.0.ffn.layers.1.weight - torch.Size([2048, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,029 - mmcv - INFO - \n",
            "backbone.layers.3.1.0.ffn.layers.1.bias - torch.Size([2048]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,029 - mmcv - INFO - \n",
            "backbone.layers.3.1.0.ffn.layers.4.weight - torch.Size([512, 2048, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,029 - mmcv - INFO - \n",
            "backbone.layers.3.1.0.ffn.layers.4.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,029 - mmcv - INFO - \n",
            "backbone.layers.3.1.1.norm1.weight - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,029 - mmcv - INFO - \n",
            "backbone.layers.3.1.1.norm1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,029 - mmcv - INFO - \n",
            "backbone.layers.3.1.1.attn.attn.in_proj_weight - torch.Size([1536, 512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,029 - mmcv - INFO - \n",
            "backbone.layers.3.1.1.attn.attn.in_proj_bias - torch.Size([1536]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,029 - mmcv - INFO - \n",
            "backbone.layers.3.1.1.attn.attn.out_proj.weight - torch.Size([512, 512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,029 - mmcv - INFO - \n",
            "backbone.layers.3.1.1.attn.attn.out_proj.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,029 - mmcv - INFO - \n",
            "backbone.layers.3.1.1.norm2.weight - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,030 - mmcv - INFO - \n",
            "backbone.layers.3.1.1.norm2.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,030 - mmcv - INFO - \n",
            "backbone.layers.3.1.1.ffn.layers.0.weight - torch.Size([2048, 512, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,030 - mmcv - INFO - \n",
            "backbone.layers.3.1.1.ffn.layers.0.bias - torch.Size([2048]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,030 - mmcv - INFO - \n",
            "backbone.layers.3.1.1.ffn.layers.1.weight - torch.Size([2048, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,030 - mmcv - INFO - \n",
            "backbone.layers.3.1.1.ffn.layers.1.bias - torch.Size([2048]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,030 - mmcv - INFO - \n",
            "backbone.layers.3.1.1.ffn.layers.4.weight - torch.Size([512, 2048, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,030 - mmcv - INFO - \n",
            "backbone.layers.3.1.1.ffn.layers.4.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,030 - mmcv - INFO - \n",
            "backbone.layers.3.1.2.norm1.weight - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,030 - mmcv - INFO - \n",
            "backbone.layers.3.1.2.norm1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,031 - mmcv - INFO - \n",
            "backbone.layers.3.1.2.attn.attn.in_proj_weight - torch.Size([1536, 512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,031 - mmcv - INFO - \n",
            "backbone.layers.3.1.2.attn.attn.in_proj_bias - torch.Size([1536]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,031 - mmcv - INFO - \n",
            "backbone.layers.3.1.2.attn.attn.out_proj.weight - torch.Size([512, 512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,031 - mmcv - INFO - \n",
            "backbone.layers.3.1.2.attn.attn.out_proj.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,031 - mmcv - INFO - \n",
            "backbone.layers.3.1.2.norm2.weight - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,031 - mmcv - INFO - \n",
            "backbone.layers.3.1.2.norm2.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,031 - mmcv - INFO - \n",
            "backbone.layers.3.1.2.ffn.layers.0.weight - torch.Size([2048, 512, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,031 - mmcv - INFO - \n",
            "backbone.layers.3.1.2.ffn.layers.0.bias - torch.Size([2048]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,031 - mmcv - INFO - \n",
            "backbone.layers.3.1.2.ffn.layers.1.weight - torch.Size([2048, 1, 3, 3]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,032 - mmcv - INFO - \n",
            "backbone.layers.3.1.2.ffn.layers.1.bias - torch.Size([2048]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,032 - mmcv - INFO - \n",
            "backbone.layers.3.1.2.ffn.layers.4.weight - torch.Size([512, 2048, 1, 1]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,032 - mmcv - INFO - \n",
            "backbone.layers.3.1.2.ffn.layers.4.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,032 - mmcv - INFO - \n",
            "backbone.layers.3.2.weight - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,032 - mmcv - INFO - \n",
            "backbone.layers.3.2.bias - torch.Size([512]): \n",
            "PretrainedInit: load from ./pretrained_models/mit_b4_mmseg.pth \n",
            " \n",
            "2023-10-07 17:22:44,032 - mmcv - INFO - \n",
            "decode_head.conv_seg.weight - torch.Size([3, 256, 1, 1]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2023-10-07 17:22:44,032 - mmcv - INFO - \n",
            "decode_head.conv_seg.bias - torch.Size([3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2023-10-07 17:22:44,032 - mmcv - INFO - \n",
            "decode_head.convs.0.conv.weight - torch.Size([256, 64, 1, 1]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "2023-10-07 17:22:44,032 - mmcv - INFO - \n",
            "decode_head.convs.0.bn.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "2023-10-07 17:22:44,033 - mmcv - INFO - \n",
            "decode_head.convs.0.bn.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "2023-10-07 17:22:44,033 - mmcv - INFO - \n",
            "decode_head.convs.1.conv.weight - torch.Size([256, 128, 1, 1]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "2023-10-07 17:22:44,033 - mmcv - INFO - \n",
            "decode_head.convs.1.bn.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "2023-10-07 17:22:44,033 - mmcv - INFO - \n",
            "decode_head.convs.1.bn.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "2023-10-07 17:22:44,033 - mmcv - INFO - \n",
            "decode_head.convs.2.conv.weight - torch.Size([256, 320, 1, 1]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "2023-10-07 17:22:44,033 - mmcv - INFO - \n",
            "decode_head.convs.2.bn.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "2023-10-07 17:22:44,033 - mmcv - INFO - \n",
            "decode_head.convs.2.bn.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "2023-10-07 17:22:44,033 - mmcv - INFO - \n",
            "decode_head.convs.3.conv.weight - torch.Size([256, 512, 1, 1]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "2023-10-07 17:22:44,033 - mmcv - INFO - \n",
            "decode_head.convs.3.bn.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "2023-10-07 17:22:44,034 - mmcv - INFO - \n",
            "decode_head.convs.3.bn.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "2023-10-07 17:22:44,034 - mmcv - INFO - \n",
            "decode_head.fusion_conv.conv.weight - torch.Size([256, 1024, 1, 1]): \n",
            "Initialized by user-defined `init_weights` in ConvModule  \n",
            " \n",
            "2023-10-07 17:22:44,034 - mmcv - INFO - \n",
            "decode_head.fusion_conv.bn.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "2023-10-07 17:22:44,034 - mmcv - INFO - \n",
            "decode_head.fusion_conv.bn.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n"
          ]
        }
      ],
      "source": [
        "#device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#model settings\n",
        "norm_cfg = dict(type='BN', requires_grad=True)\n",
        "model_cfg = dict(\n",
        "    type='EncoderDecoder',\n",
        "    pretrained=None,\n",
        "    backbone=dict(\n",
        "        type='MixVisionTransformer',\n",
        "        in_channels=3,\n",
        "        embed_dims=64,\n",
        "        num_stages=4,\n",
        "        num_layers=[3, 8, 27, 3],\n",
        "        num_heads=[1, 2, 5, 8],\n",
        "        patch_sizes=[7, 3, 3, 3],\n",
        "        sr_ratios=[8, 4, 2, 1],\n",
        "        out_indices=(0, 1, 2, 3),\n",
        "        mlp_ratio=4,\n",
        "        qkv_bias=True,\n",
        "        drop_rate=0.0,\n",
        "        attn_drop_rate=0.0,\n",
        "        drop_path_rate=0.1,\n",
        "        init_cfg = dict(type=\"Pretrained\", checkpoint=\"./pretrained_models/mit_b4_mmseg.pth\")),\n",
        "    decode_head=dict(\n",
        "        type='SegformerHead',\n",
        "        in_channels=[64, 128, 320, 512],\n",
        "        in_index=[0, 1, 2, 3],\n",
        "        channels=256,\n",
        "        dropout_ratio=0.1,\n",
        "        num_classes=3,\n",
        "        norm_cfg=norm_cfg,\n",
        "        align_corners=False,\n",
        "        loss_decode=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n",
        "    # model training and testing settings\n",
        "    train_cfg=dict(),\n",
        "    test_cfg=dict(mode='whole'))\n",
        "\n",
        "\n",
        "#load data\n",
        "batch_size = 12\n",
        "n_workers = os.cpu_count()\n",
        "print(\"num_workers =\", n_workers)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=n_workers)\n",
        "\n",
        "import mmcv\n",
        "from mmseg.models import build_segmentor\n",
        "model = build_segmentor(model_cfg).to(device)\n",
        "model.init_weights()\n",
        "\n",
        "#loss\n",
        "criterion = FocalLoss_Ori(num_class=3)\n",
        "\n",
        "#optimizer\n",
        "n_eps = 50\n",
        "init_lr = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=init_lr)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader)*n_eps, eta_min=init_lr/100)\n",
        "total_step = len(train_loader)\n",
        "\n",
        "#meter\n",
        "train_loss_meter = AverageMeter()\n",
        "intersection_meter = AverageMeter()\n",
        "union_meter = AverageMeter()\n",
        "target_meter = AverageMeter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TyVvQtbpv1WW"
      },
      "outputs": [
=======
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/pervinco/mmsegmentation/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/home/pervinco/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_large_patch4_window12_384_22k_20220412-6580f57d.pth\n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.patch_embed.projection.weight - torch.Size([192, 3, 4, 4]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.patch_embed.projection.bias - torch.Size([192]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.patch_embed.norm.weight - torch.Size([192]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.patch_embed.norm.bias - torch.Size([192]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.0.norm1.weight - torch.Size([192]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.0.norm1.bias - torch.Size([192]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([529, 6]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.0.attn.w_msa.qkv.weight - torch.Size([576, 192]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.0.attn.w_msa.qkv.bias - torch.Size([576]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.0.attn.w_msa.proj.weight - torch.Size([192, 192]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.0.attn.w_msa.proj.bias - torch.Size([192]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.0.norm2.weight - torch.Size([192]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.0.norm2.bias - torch.Size([192]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.0.ffn.layers.0.0.weight - torch.Size([768, 192]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.0.ffn.layers.0.0.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.0.ffn.layers.1.weight - torch.Size([192, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.0.ffn.layers.1.bias - torch.Size([192]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.1.norm1.weight - torch.Size([192]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.1.norm1.bias - torch.Size([192]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([529, 6]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.1.attn.w_msa.qkv.weight - torch.Size([576, 192]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.1.attn.w_msa.qkv.bias - torch.Size([576]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.1.attn.w_msa.proj.weight - torch.Size([192, 192]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.1.attn.w_msa.proj.bias - torch.Size([192]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.1.norm2.weight - torch.Size([192]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.1.norm2.bias - torch.Size([192]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.1.ffn.layers.0.0.weight - torch.Size([768, 192]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.1.ffn.layers.0.0.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.1.ffn.layers.1.weight - torch.Size([192, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.blocks.1.ffn.layers.1.bias - torch.Size([192]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.downsample.norm.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.downsample.norm.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.0.downsample.reduction.weight - torch.Size([384, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.0.norm1.weight - torch.Size([384]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.0.norm1.bias - torch.Size([384]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([529, 12]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.0.attn.w_msa.qkv.weight - torch.Size([1152, 384]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.0.attn.w_msa.qkv.bias - torch.Size([1152]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.0.attn.w_msa.proj.weight - torch.Size([384, 384]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.0.attn.w_msa.proj.bias - torch.Size([384]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.0.norm2.weight - torch.Size([384]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.0.norm2.bias - torch.Size([384]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.0.ffn.layers.0.0.weight - torch.Size([1536, 384]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.0.ffn.layers.0.0.bias - torch.Size([1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.0.ffn.layers.1.weight - torch.Size([384, 1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.0.ffn.layers.1.bias - torch.Size([384]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.1.norm1.weight - torch.Size([384]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.1.norm1.bias - torch.Size([384]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([529, 12]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.1.attn.w_msa.qkv.weight - torch.Size([1152, 384]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.1.attn.w_msa.qkv.bias - torch.Size([1152]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.1.attn.w_msa.proj.weight - torch.Size([384, 384]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.1.attn.w_msa.proj.bias - torch.Size([384]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.1.norm2.weight - torch.Size([384]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.1.norm2.bias - torch.Size([384]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.1.ffn.layers.0.0.weight - torch.Size([1536, 384]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.1.ffn.layers.0.0.bias - torch.Size([1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.1.ffn.layers.1.weight - torch.Size([384, 1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.blocks.1.ffn.layers.1.bias - torch.Size([384]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.downsample.norm.weight - torch.Size([1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.downsample.norm.bias - torch.Size([1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.1.downsample.reduction.weight - torch.Size([768, 1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.0.norm1.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.0.norm1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.0.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.0.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.0.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.0.attn.w_msa.proj.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.0.norm2.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.0.norm2.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.0.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.0.ffn.layers.0.0.bias - torch.Size([3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.0.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.0.ffn.layers.1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.1.norm1.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.1.norm1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.1.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.1.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.1.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.1.attn.w_msa.proj.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.1.norm2.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.1.norm2.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.1.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.1.ffn.layers.0.0.bias - torch.Size([3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.1.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.1.ffn.layers.1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.2.norm1.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.2.norm1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.2.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.2.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.2.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.2.attn.w_msa.proj.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.2.norm2.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.2.norm2.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.2.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.2.ffn.layers.0.0.bias - torch.Size([3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.2.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.2.ffn.layers.1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.3.norm1.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.3.norm1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.3.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.3.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.3.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.3.attn.w_msa.proj.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.3.norm2.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.3.norm2.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.3.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.3.ffn.layers.0.0.bias - torch.Size([3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.3.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.3.ffn.layers.1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.4.norm1.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.4.norm1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.4.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.4.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.4.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.4.attn.w_msa.proj.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.4.norm2.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.4.norm2.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.4.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.4.ffn.layers.0.0.bias - torch.Size([3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.4.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.4.ffn.layers.1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.5.norm1.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.5.norm1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.5.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.5.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.5.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.5.attn.w_msa.proj.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.5.norm2.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.5.norm2.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.5.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.5.ffn.layers.0.0.bias - torch.Size([3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.5.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.5.ffn.layers.1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.6.norm1.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.6.norm1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.6.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.6.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.6.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.6.attn.w_msa.proj.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.6.norm2.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.6.norm2.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.6.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.6.ffn.layers.0.0.bias - torch.Size([3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.6.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.6.ffn.layers.1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.7.norm1.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.7.norm1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.7.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.7.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.7.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.7.attn.w_msa.proj.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.7.norm2.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.7.norm2.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.7.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.7.ffn.layers.0.0.bias - torch.Size([3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.7.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.7.ffn.layers.1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.8.norm1.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.8.norm1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.8.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.8.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.8.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.8.attn.w_msa.proj.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.8.norm2.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.8.norm2.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.8.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.8.ffn.layers.0.0.bias - torch.Size([3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.8.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.8.ffn.layers.1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.9.norm1.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.9.norm1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.9.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.9.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.9.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.9.attn.w_msa.proj.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.9.norm2.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.9.norm2.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.9.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.9.ffn.layers.0.0.bias - torch.Size([3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.9.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.9.ffn.layers.1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.10.norm1.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.10.norm1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.10.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.10.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.10.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.10.attn.w_msa.proj.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.10.norm2.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.10.norm2.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.10.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.10.ffn.layers.0.0.bias - torch.Size([3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.10.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.10.ffn.layers.1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.11.norm1.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.11.norm1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.11.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.11.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.11.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.11.attn.w_msa.proj.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.11.norm2.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.11.norm2.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.11.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.11.ffn.layers.0.0.bias - torch.Size([3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.11.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.11.ffn.layers.1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.12.norm1.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.12.norm1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.12.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.12.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.12.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.12.attn.w_msa.proj.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.12.norm2.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.12.norm2.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.12.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.12.ffn.layers.0.0.bias - torch.Size([3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.12.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.12.ffn.layers.1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.13.norm1.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.13.norm1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.13.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.13.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.13.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.13.attn.w_msa.proj.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.13.norm2.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.13.norm2.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.13.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.13.ffn.layers.0.0.bias - torch.Size([3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.13.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.13.ffn.layers.1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.14.norm1.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.14.norm1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.14.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.14.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.14.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.14.attn.w_msa.proj.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.14.norm2.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.14.norm2.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.14.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.14.ffn.layers.0.0.bias - torch.Size([3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.14.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.14.ffn.layers.1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.15.norm1.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.15.norm1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.15.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.15.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.15.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.15.attn.w_msa.proj.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.15.norm2.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.15.norm2.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.15.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.15.ffn.layers.0.0.bias - torch.Size([3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.15.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.15.ffn.layers.1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.16.norm1.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.16.norm1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.16.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.16.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.16.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.16.attn.w_msa.proj.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.16.norm2.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.16.norm2.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.16.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.16.ffn.layers.0.0.bias - torch.Size([3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.16.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.16.ffn.layers.1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.17.norm1.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.17.norm1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.17.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.17.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.17.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.17.attn.w_msa.proj.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.17.norm2.weight - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.17.norm2.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.17.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.17.ffn.layers.0.0.bias - torch.Size([3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.17.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.blocks.17.ffn.layers.1.bias - torch.Size([768]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.downsample.norm.weight - torch.Size([3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.downsample.norm.bias - torch.Size([3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.2.downsample.reduction.weight - torch.Size([1536, 3072]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.0.norm1.weight - torch.Size([1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.0.norm1.bias - torch.Size([1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([529, 48]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.0.attn.w_msa.qkv.weight - torch.Size([4608, 1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.0.attn.w_msa.qkv.bias - torch.Size([4608]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.0.attn.w_msa.proj.weight - torch.Size([1536, 1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.0.attn.w_msa.proj.bias - torch.Size([1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.0.norm2.weight - torch.Size([1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.0.norm2.bias - torch.Size([1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.0.ffn.layers.0.0.weight - torch.Size([6144, 1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.0.ffn.layers.0.0.bias - torch.Size([6144]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.0.ffn.layers.1.weight - torch.Size([1536, 6144]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.0.ffn.layers.1.bias - torch.Size([1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.1.norm1.weight - torch.Size([1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.1.norm1.bias - torch.Size([1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([529, 48]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.1.attn.w_msa.qkv.weight - torch.Size([4608, 1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.1.attn.w_msa.qkv.bias - torch.Size([4608]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.1.attn.w_msa.proj.weight - torch.Size([1536, 1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.1.attn.w_msa.proj.bias - torch.Size([1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.1.norm2.weight - torch.Size([1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.1.norm2.bias - torch.Size([1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.1.ffn.layers.0.0.weight - torch.Size([6144, 1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.1.ffn.layers.0.0.bias - torch.Size([6144]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.1.ffn.layers.1.weight - torch.Size([1536, 6144]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.stages.3.blocks.1.ffn.layers.1.bias - torch.Size([1536]): \n",
            "Initialized by user-defined `init_weights` in SwinTransformer  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.norm0.weight - torch.Size([192]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.norm0.bias - torch.Size([192]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.norm1.weight - torch.Size([384]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.norm1.bias - torch.Size([384]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.norm2.weight - torch.Size([768]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.norm2.bias - torch.Size([768]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.norm3.weight - torch.Size([1536]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "backbone.norm3.bias - torch.Size([1536]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.conv_seg.weight - torch.Size([3, 512, 1, 1]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.conv_seg.bias - torch.Size([3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.psp_modules.0.1.conv.weight - torch.Size([512, 1536, 1, 1]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.psp_modules.0.1.bn.weight - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.psp_modules.0.1.bn.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.psp_modules.1.1.conv.weight - torch.Size([512, 1536, 1, 1]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.psp_modules.1.1.bn.weight - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.psp_modules.1.1.bn.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.psp_modules.2.1.conv.weight - torch.Size([512, 1536, 1, 1]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.psp_modules.2.1.bn.weight - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.psp_modules.2.1.bn.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.psp_modules.3.1.conv.weight - torch.Size([512, 1536, 1, 1]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.psp_modules.3.1.bn.weight - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.psp_modules.3.1.bn.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.bottleneck.conv.weight - torch.Size([512, 3584, 3, 3]): \n",
            "Initialized by user-defined `init_weights` in ConvModule  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.bottleneck.bn.weight - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.bottleneck.bn.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.lateral_convs.0.conv.weight - torch.Size([512, 192, 1, 1]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.lateral_convs.0.bn.weight - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.lateral_convs.0.bn.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.lateral_convs.1.conv.weight - torch.Size([512, 384, 1, 1]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.lateral_convs.1.bn.weight - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.lateral_convs.1.bn.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.lateral_convs.2.conv.weight - torch.Size([512, 768, 1, 1]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.lateral_convs.2.bn.weight - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.lateral_convs.2.bn.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.fpn_convs.0.conv.weight - torch.Size([512, 512, 3, 3]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.fpn_convs.0.bn.weight - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.fpn_convs.0.bn.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.fpn_convs.1.conv.weight - torch.Size([512, 512, 3, 3]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.fpn_convs.1.bn.weight - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.fpn_convs.1.bn.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.fpn_convs.2.conv.weight - torch.Size([512, 512, 3, 3]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.fpn_convs.2.bn.weight - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.fpn_convs.2.bn.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.fpn_bottleneck.conv.weight - torch.Size([512, 2048, 3, 3]): \n",
            "Initialized by user-defined `init_weights` in ConvModule  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.fpn_bottleneck.bn.weight - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "decode_head.fpn_bottleneck.bn.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "auxiliary_head.conv_seg.weight - torch.Size([3, 256, 1, 1]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "auxiliary_head.conv_seg.bias - torch.Size([3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "auxiliary_head.convs.0.conv.weight - torch.Size([256, 768, 3, 3]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "auxiliary_head.convs.0.bn.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n",
            "10/10 15:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "auxiliary_head.convs.0.bn.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
            " \n"
          ]
        }
      ],
      "source": [
        "#device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "norm_cfg = dict(type='BN', requires_grad=True)\n",
        "# checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b4_20220624-d588d980.pth'  # noqa\n",
        "# model = dict(\n",
        "#     type='EncoderDecoder',\n",
        "#     pretrained=None,\n",
        "#     backbone=dict(\n",
        "#         type='MixVisionTransformer',\n",
        "#         in_channels=3,\n",
        "#         embed_dims=64,\n",
        "#         num_stages=4,\n",
        "#         num_layers=[3, 8, 27, 3],\n",
        "#         num_heads=[1, 2, 5, 8],\n",
        "#         patch_sizes=[7, 3, 3, 3],\n",
        "#         sr_ratios=[8, 4, 2, 1],\n",
        "#         out_indices=(0, 1, 2, 3),\n",
        "#         mlp_ratio=4,\n",
        "#         qkv_bias=True,\n",
        "#         drop_rate=0.0,\n",
        "#         attn_drop_rate=0.0,\n",
        "#         drop_path_rate=0.,\n",
        "#         init_cfg = dict(type=\"Pretrained\", checkpoint=checkpoint)),\n",
        "#     decode_head=dict(\n",
        "#         type='SegformerHead',\n",
        "#         in_channels=[64, 128, 320, 512],\n",
        "#         in_index=[0, 1, 2, 3],\n",
        "#         channels=256,\n",
        "#         dropout_ratio=0.1,\n",
        "#         num_classes=config[\"num_classes\"],\n",
        "#         norm_cfg=norm_cfg,\n",
        "#         align_corners=False,\n",
        "#         loss_decode=dict(type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n",
        "#     train_cfg=dict())\n",
        "\n",
        "backbone_norm_cfg = dict(type='LN', requires_grad=True)\n",
        "# checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_large_patch4_window12_384_22k_20220412-6580f57d.pth'  # noqa\n",
        "# model_cfg = dict(\n",
        "#     type='EncoderDecoder',\n",
        "#     pretrained=None,\n",
        "#     backbone=dict(\n",
        "#         type='SwinTransformer',\n",
        "#         pretrain_img_size=config[\"img_size\"],\n",
        "#         embed_dims=192,\n",
        "#         patch_size=4,\n",
        "#         mlp_ratio=4,\n",
        "#         window_size=12,\n",
        "#         depths=[2, 2, 18, 2],\n",
        "#         num_heads=[6, 12, 24, 48],\n",
        "#         strides=(4, 2, 2, 2),\n",
        "#         out_indices=(0, 1, 2, 3),\n",
        "#         qkv_bias=True,\n",
        "#         qk_scale=None,\n",
        "#         patch_norm=True,\n",
        "#         drop_rate=0.,\n",
        "#         attn_drop_rate=0.,\n",
        "#         drop_path_rate=0.3,\n",
        "#         use_abs_pos_embed=False,\n",
        "#         act_cfg=dict(type='GELU'),\n",
        "#         norm_cfg=backbone_norm_cfg,\n",
        "#         init_cfg=dict(type='Pretrained', checkpoint=checkpoint_file)),\n",
        "#     decode_head=dict(\n",
        "#         type='UPerHead',\n",
        "#         in_channels=[192, 384, 768, 1536],\n",
        "#         in_index=[0, 1, 2, 3],\n",
        "#         pool_scales=(1, 2, 3, 6),\n",
        "#         channels=512,\n",
        "#         dropout_ratio=0.1,\n",
        "#         num_classes=config[\"num_classes\"],\n",
        "#         norm_cfg=norm_cfg,\n",
        "#         align_corners=False,\n",
        "#         loss_decode=dict(\n",
        "#             type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n",
        "#     auxiliary_head=dict(\n",
        "#         type='FCNHead',\n",
        "#         in_channels=768,\n",
        "#         in_index=2,\n",
        "#         channels=256,\n",
        "#         num_convs=1,\n",
        "#         concat_input=False,\n",
        "#         dropout_ratio=0.1,\n",
        "#         num_classes=config[\"num_classes\"],\n",
        "#         norm_cfg=norm_cfg,\n",
        "#         align_corners=False,\n",
        "#         loss_decode=dict(\n",
        "#             type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n",
        "#     # model training and testing settings\n",
        "#     train_cfg=dict(),\n",
        "#     test_cfg=dict(mode='whole'))\n",
        "\n",
        "checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_large_patch4_window7_224_22k_20220412-aeecf2aa.pth'  # noqa\n",
        "model_cfg = dict(\n",
        "    type='EncoderDecoder',\n",
        "    pretrained=None,\n",
        "    backbone=dict(\n",
        "        type='SwinTransformer',\n",
        "        pretrain_img_size=config[\"img_size\"],\n",
        "        embed_dims=192,\n",
        "        patch_size=4,\n",
        "        mlp_ratio=4,\n",
        "        window_size=12,\n",
        "        depths=[2, 2, 18, 2],\n",
        "        num_heads=[6, 12, 24, 48],\n",
        "        strides=(4, 2, 2, 2),\n",
        "        out_indices=(0, 1, 2, 3),\n",
        "        qkv_bias=True,\n",
        "        qk_scale=None,\n",
        "        patch_norm=True,\n",
        "        drop_rate=0.,\n",
        "        attn_drop_rate=0.,\n",
        "        drop_path_rate=0.3,\n",
        "        use_abs_pos_embed=False,\n",
        "        act_cfg=dict(type='GELU'),\n",
        "        norm_cfg=backbone_norm_cfg,\n",
        "        init_cfg=dict(type='Pretrained', checkpoint=checkpoint_file)),\n",
        "    decode_head=dict(\n",
        "        type='UPerHead',\n",
        "        in_channels=[192, 384, 768, 1536],\n",
        "        in_index=[0, 1, 2, 3],\n",
        "        pool_scales=(1, 2, 3, 6),\n",
        "        channels=512,\n",
        "        dropout_ratio=0.1,\n",
        "        num_classes=config[\"num_classes\"],\n",
        "        norm_cfg=norm_cfg,\n",
        "        align_corners=False,\n",
        "        loss_decode=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n",
        "    auxiliary_head=dict(in_channels=768, num_classes=config[\"num_classes\"]))\n",
        "\n",
        "model = build_segmentor(model_cfg).to(device)\n",
        "model.init_weights()\n",
        "\n",
        "#loss\n",
        "criterion = FocalLoss_Ori(num_class=3)\n",
        "\n",
        "#optimizer\n",
        "n_eps = config[\"epochs\"]\n",
        "init_lr = config[\"init_lr\"]\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=init_lr)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_dataloader)*n_eps, eta_min=init_lr/100)\n",
        "total_step = len(train_dataloader)\n",
        "\n",
        "#meter\n",
        "train_loss_meter = AverageMeter()\n",
        "intersection_meter = AverageMeter()\n",
        "union_meter = AverageMeter()\n",
        "target_meter = AverageMeter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./runs/2023-10-10_15-52-48\n"
          ]
        }
      ],
      "source": [
        "## Save Config\n",
        "save_dir = config[\"save_dir\"]\n",
        "current_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "save_path = f\"{save_dir}/{current_time}\"\n",
        "\n",
        "if not os.path.isdir(save_path):\n",
        "    print(save_path)\n",
        "    os.makedirs(f\"{save_path}/weights\")\n",
        "    config[\"save_dir\"] = save_path\n",
        "\n",
        "save_config_to_yaml(config, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TyVvQtbpv1WW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:52<00:00,  2.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 1, current_lr = [0.0001], train_loss = 0.2471, IoU = 0.1459, dice = 0.2317 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 2, current_lr = [9.997557473810375e-05], train_loss = 0.0505, IoU = 0.3796, dice = 0.4892 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:52<00:00,  2.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 3, current_lr = [9.990232305719958e-05], train_loss = 0.0325, IoU = 0.4786, dice = 0.6112 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:52<00:00,  2.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 4, current_lr = [9.978031724785267e-05], train_loss = 0.0291, IoU = 0.5204, dice = 0.6571 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:50<00:00,  2.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 5, current_lr = [9.960967771506686e-05], train_loss = 0.0244, IoU = 0.5585, dice = 0.6926 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:52<00:00,  2.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 6, current_lr = [9.939057285945944e-05], train_loss = 0.0230, IoU = 0.5820, dice = 0.7164 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:50<00:00,  2.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 7, current_lr = [9.912321891107021e-05], train_loss = 0.0192, IoU = 0.6297, dice = 0.7585 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 8, current_lr = [9.880787971596807e-05], train_loss = 0.0187, IoU = 0.6317, dice = 0.7609 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 9, current_lr = [9.84448664758673e-05], train_loss = 0.0175, IoU = 0.6587, dice = 0.7818 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 10, current_lr = [9.803453744100873e-05], train_loss = 0.0159, IoU = 0.6820, dice = 0.8017 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 11, current_lr = [9.75772975566101e-05], train_loss = 0.0172, IoU = 0.6528, dice = 0.7773 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:52<00:00,  2.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 12, current_lr = [9.707359806323412e-05], train_loss = 0.0155, IoU = 0.6709, dice = 0.7919 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 13, current_lr = [9.652393605146843e-05], train_loss = 0.0119, IoU = 0.7567, dice = 0.8569 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 14, current_lr = [9.592885397135707e-05], train_loss = 0.0129, IoU = 0.7364, dice = 0.8423 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 15, current_lr = [9.528893909706792e-05], train_loss = 0.0109, IoU = 0.7827, dice = 0.8752 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 16, current_lr = [9.46048229473242e-05], train_loss = 0.0130, IoU = 0.7474, dice = 0.8503 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:52<00:00,  2.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 17, current_lr = [9.38771806621712e-05], train_loss = 0.0102, IoU = 0.7788, dice = 0.8719 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:52<00:00,  2.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 18, current_lr = [9.31067303366952e-05], train_loss = 0.0093, IoU = 0.7973, dice = 0.8842 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 19, current_lr = [9.229423231234974e-05], train_loss = 0.0142, IoU = 0.6840, dice = 0.8010 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 20, current_lr = [9.144048842659087e-05], train_loss = 0.0109, IoU = 0.7770, dice = 0.8714 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 21, current_lr = [9.054634122156004e-05], train_loss = 0.0130, IoU = 0.7190, dice = 0.8291 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:52<00:00,  2.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 22, current_lr = [8.961267311259685e-05], train_loss = 0.0094, IoU = 0.7818, dice = 0.8739 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:52<00:00,  2.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 23, current_lr = [8.864040551740171e-05], train_loss = 0.0086, IoU = 0.8165, dice = 0.8967 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 24, current_lr = [8.763049794670801e-05], train_loss = 0.0081, IoU = 0.8079, dice = 0.8911 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 25, current_lr = [8.658394705736e-05], train_loss = 0.0084, IoU = 0.8236, dice = 0.9013 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 26, current_lr = [8.55017856687342e-05], train_loss = 0.0120, IoU = 0.7699, dice = 0.8660 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 27, current_lr = [8.438508174347025e-05], train_loss = 0.0089, IoU = 0.8113, dice = 0.8936 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 28, current_lr = [8.323493733352088e-05], train_loss = 0.0086, IoU = 0.8190, dice = 0.8982 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 29, current_lr = [8.20524874925602e-05], train_loss = 0.0078, IoU = 0.8379, dice = 0.9102 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 30, current_lr = [8.083889915582253e-05], train_loss = 0.0074, IoU = 0.8367, dice = 0.9093 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 31, current_lr = [7.959536998847757e-05], train_loss = 0.0083, IoU = 0.8201, dice = 0.8991 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:52<00:00,  2.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 32, current_lr = [7.832312720368066e-05], train_loss = 0.0078, IoU = 0.8343, dice = 0.9079 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 33, current_lr = [7.70234263514605e-05], train_loss = 0.0086, IoU = 0.7990, dice = 0.8850 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:52<00:00,  2.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 34, current_lr = [7.569755007964345e-05], train_loss = 0.0065, IoU = 0.8489, dice = 0.9169 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:52<00:00,  2.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 35, current_lr = [7.434680686803488e-05], train_loss = 0.0065, IoU = 0.8455, dice = 0.9146 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:52<00:00,  2.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 36, current_lr = [7.297252973710754e-05], train_loss = 0.0082, IoU = 0.8163, dice = 0.8965 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:52<00:00,  2.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 37, current_lr = [7.15760749324711e-05], train_loss = 0.0068, IoU = 0.8564, dice = 0.9215 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 38, current_lr = [7.015882058642164e-05], train_loss = 0.0059, IoU = 0.8654, dice = 0.9268 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 39, current_lr = [6.872216535789163e-05], train_loss = 0.0060, IoU = 0.8705, dice = 0.9299 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 40, current_lr = [6.726752705214191e-05], train_loss = 0.0066, IoU = 0.8552, dice = 0.9208 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 41, current_lr = [6.579634122155991e-05], train_loss = 0.0061, IoU = 0.8545, dice = 0.9200 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:52<00:00,  2.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 42, current_lr = [6.431005974894189e-05], train_loss = 0.0061, IoU = 0.8520, dice = 0.9185 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:52<00:00,  2.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 43, current_lr = [6.281014941466036e-05], train_loss = 0.0073, IoU = 0.8151, dice = 0.8954 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:52<00:00,  2.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 44, current_lr = [6.12980904491291e-05], train_loss = 0.0090, IoU = 0.8103, dice = 0.8928 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:52<00:00,  2.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 45, current_lr = [5.977537507199373e-05], train_loss = 0.0065, IoU = 0.8508, dice = 0.9179 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:52<00:00,  2.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 46, current_lr = [5.82435060194918e-05], train_loss = 0.0102, IoU = 0.8043, dice = 0.8885 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 47, current_lr = [5.6703995061433434e-05], train_loss = 0.0066, IoU = 0.8454, dice = 0.9146 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:52<00:00,  2.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 48, current_lr = [5.51583615092668e-05], train_loss = 0.0058, IoU = 0.8667, dice = 0.9277 \n",
            "\n"
          ]
        },
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:20<00:00,  4.07it/s]\n"
=======
            "100%|| 125/125 [00:52<00:00,  2.39it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 1, current_lr = [0.0001] , train loss = 0.35166803871591884 IoU = 0.10087216645479202, dice = 0.17020472884178162\n"
=======
            "EP : 49, current_lr = [5.3608130716701324e-05], train_loss = 0.0058, IoU = 0.8711, dice = 0.9302 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.41it/s]\n"
=======
            "100%|| 125/125 [00:52<00:00,  2.39it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 2, current_lr = [9.990232305719946e-05] , train loss = 0.08218349019686381 IoU = 0.32068538665771484, dice = 0.39144816994667053\n"
=======
            "EP : 50, current_lr = [5.2054832574367643e-05], train_loss = 0.0057, IoU = 0.8803, dice = 0.9356 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.40it/s]\n"
=======
            "100%|| 125/125 [00:52<00:00,  2.39it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 3, current_lr = [9.960967771506667e-05] , train loss = 0.03633305224190865 IoU = 0.42001909017562866, dice = 0.5098804831504822\n"
=======
            "EP : 51, current_lr = [5.0500000000000286e-05], train_loss = 0.0055, IoU = 0.8757, dice = 0.9329 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.35it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.44it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 4, current_lr = [9.912321891107013e-05] , train loss = 0.02441888497698875 IoU = 0.5368354916572571, dice = 0.6630304455757141\n"
=======
            "EP : 52, current_lr = [4.894516742563292e-05], train_loss = 0.0055, IoU = 0.8757, dice = 0.9329 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.30it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 5, current_lr = [9.84448664758673e-05] , train loss = 0.019337933843157122 IoU = 0.5662869811058044, dice = 0.693234384059906\n"
=======
            "EP : 53, current_lr = [4.739186928329925e-05], train_loss = 0.0052, IoU = 0.8809, dice = 0.9360 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.36it/s]\n"
=======
            "100%|| 125/125 [00:52<00:00,  2.39it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 6, current_lr = [9.757729755661011e-05] , train loss = 0.015260313648641818 IoU = 0.6353418827056885, dice = 0.7563971281051636\n"
=======
            "EP : 54, current_lr = [4.5841638490733826e-05], train_loss = 0.0056, IoU = 0.8729, dice = 0.9313 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.34it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 7, current_lr = [9.652393605146848e-05] , train loss = 0.014982563620876698 IoU = 0.5794715285301208, dice = 0.7033432722091675\n"
=======
            "EP : 55, current_lr = [4.4296004938567226e-05], train_loss = 0.0056, IoU = 0.8736, dice = 0.9317 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.38it/s]\n"
=======
            "100%|| 125/125 [00:52<00:00,  2.39it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 8, current_lr = [9.528893909706808e-05] , train loss = 0.011651879825097109 IoU = 0.6604800224304199, dice = 0.7791717052459717\n"
=======
            "EP : 56, current_lr = [4.275649398050884e-05], train_loss = 0.0051, IoU = 0.8830, dice = 0.9372 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.34it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.43it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 9, current_lr = [9.387718066217131e-05] , train loss = 0.011985705555638387 IoU = 0.6487597823143005, dice = 0.7687530517578125\n"
=======
            "EP : 57, current_lr = [4.12246249280069e-05], train_loss = 0.0048, IoU = 0.8878, dice = 0.9399 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.40it/s]\n"
=======
            "100%|| 125/125 [00:52<00:00,  2.40it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 10, current_lr = [9.22942323123498e-05] , train loss = 0.01149282991952662 IoU = 0.6553416848182678, dice = 0.7748109102249146\n"
=======
            "EP : 58, current_lr = [3.97019095508714e-05], train_loss = 0.0050, IoU = 0.8861, dice = 0.9389 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.41it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.40it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 11, current_lr = [9.054634122155993e-05] , train loss = 0.008619327802166697 IoU = 0.7169684171676636, dice = 0.8240659236907959\n"
=======
            "EP : 59, current_lr = [3.8189850585339904e-05], train_loss = 0.0051, IoU = 0.8824, dice = 0.9369 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.32it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 12, current_lr = [8.864040551740162e-05] , train loss = 0.009457876301547955 IoU = 0.7174783945083618, dice = 0.8269534111022949\n"
=======
            "EP : 60, current_lr = [3.6689940251058355e-05], train_loss = 0.0048, IoU = 0.8871, dice = 0.9394 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.38it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.43it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 13, current_lr = [8.658394705735991e-05] , train loss = 0.008316932473376039 IoU = 0.7199135422706604, dice = 0.8267114162445068\n"
=======
            "EP : 61, current_lr = [3.5203658778440295e-05], train_loss = 0.0046, IoU = 0.8919, dice = 0.9423 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.37it/s]\n"
=======
            "100%|| 125/125 [00:52<00:00,  2.40it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 14, current_lr = [8.43850817434702e-05] , train loss = 0.006996296542984922 IoU = 0.7691892385482788, dice = 0.8632169365882874\n"
=======
            "EP : 62, current_lr = [3.373247294785828e-05], train_loss = 0.0045, IoU = 0.8919, dice = 0.9422 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.28it/s]\n"
=======
            "100%|| 125/125 [00:50<00:00,  2.45it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 15, current_lr = [8.205248749256028e-05] , train loss = 0.00855672631379483 IoU = 0.6779949069023132, dice = 0.7937530279159546\n"
=======
            "EP : 63, current_lr = [3.2277834642108604e-05], train_loss = 0.0047, IoU = 0.8935, dice = 0.9431 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.33it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.42it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 16, current_lr = [7.95953699884776e-05] , train loss = 0.00660450380417474 IoU = 0.7731180191040039, dice = 0.8663617372512817\n"
=======
            "EP : 64, current_lr = [3.0841179413578414e-05], train_loss = 0.0043, IoU = 0.8950, dice = 0.9440 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.35it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.42it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 17, current_lr = [7.702342635146051e-05] , train loss = 0.006372208718121762 IoU = 0.7816039323806763, dice = 0.8721333146095276\n"
=======
            "EP : 65, current_lr = [2.9423925067528932e-05], train_loss = 0.0045, IoU = 0.8948, dice = 0.9440 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.35it/s]\n"
=======
            "100%|| 125/125 [00:52<00:00,  2.40it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 18, current_lr = [7.434680686803504e-05] , train loss = 0.006532574479933828 IoU = 0.7454960346221924, dice = 0.8451706171035767\n"
=======
            "EP : 66, current_lr = [2.802747026289246e-05], train_loss = 0.0047, IoU = 0.8812, dice = 0.9359 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.32it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.43it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 19, current_lr = [7.157607493247127e-05] , train loss = 0.006059415743774956 IoU = 0.7859244346618652, dice = 0.8751394152641296\n"
=======
            "EP : 67, current_lr = [2.665319313196511e-05], train_loss = 0.0044, IoU = 0.8978, dice = 0.9457 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.42it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 20, current_lr = [6.872216535789175e-05] , train loss = 0.005518035514147154 IoU = 0.8167901635169983, dice = 0.8959720730781555\n"
=======
            "EP : 68, current_lr = [2.530244992035664e-05], train_loss = 0.0046, IoU = 0.8937, dice = 0.9433 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.32it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.43it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 21, current_lr = [6.579634122156013e-05] , train loss = 0.005152435482679201 IoU = 0.817234456539154, dice = 0.8960474133491516\n"
=======
            "EP : 69, current_lr = [2.39765736485397e-05], train_loss = 0.0043, IoU = 0.8969, dice = 0.9452 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.31it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.42it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 22, current_lr = [6.281014941466059e-05] , train loss = 0.004978049133482966 IoU = 0.8163402080535889, dice = 0.8956078290939331\n"
=======
            "EP : 70, current_lr = [2.267687279631959e-05], train_loss = 0.0043, IoU = 0.8938, dice = 0.9433 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.34it/s]\n"
=======
            "100%|| 125/125 [00:52<00:00,  2.38it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 23, current_lr = [5.977537507199367e-05] , train loss = 0.0050274943683429486 IoU = 0.8111830949783325, dice = 0.8919329643249512\n"
=======
            "EP : 71, current_lr = [2.140463001152264e-05], train_loss = 0.0045, IoU = 0.8967, dice = 0.9450 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.30it/s]\n"
=======
            "100%|| 125/125 [00:52<00:00,  2.40it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 24, current_lr = [5.6703995061433325e-05] , train loss = 0.00474306878944238 IoU = 0.8345613479614258, dice = 0.907315731048584\n"
=======
            "EP : 72, current_lr = [2.0161100844177734e-05], train_loss = 0.0043, IoU = 0.8957, dice = 0.9444 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.31it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.44it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 25, current_lr = [5.360813071670131e-05] , train loss = 0.004279248374846897 IoU = 0.8395516872406006, dice = 0.9103711843490601\n"
=======
            "EP : 73, current_lr = [1.8947512507439906e-05], train_loss = 0.0045, IoU = 0.8970, dice = 0.9452 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.30it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 26, current_lr = [5.050000000000028e-05] , train loss = 0.004150761234562933 IoU = 0.8460482954978943, dice = 0.9143835306167603\n"
=======
            "EP : 74, current_lr = [1.776506266647928e-05], train_loss = 0.0041, IoU = 0.8952, dice = 0.9441 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.27it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 27, current_lr = [4.739186928329923e-05] , train loss = 0.004258544738626196 IoU = 0.8451563119888306, dice = 0.913852334022522\n"
=======
            "EP : 75, current_lr = [1.6614918256529957e-05], train_loss = 0.0042, IoU = 0.9000, dice = 0.9468 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.32it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.43it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 28, current_lr = [4.429600493856715e-05] , train loss = 0.0038049796185944053 IoU = 0.8601750135421753, dice = 0.9230579137802124\n"
=======
            "EP : 76, current_lr = [1.5498214331265877e-05], train_loss = 0.0041, IoU = 0.8966, dice = 0.9449 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.32it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.42it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 29, current_lr = [4.12246249280068e-05] , train loss = 0.0042604407506240975 IoU = 0.8404422402381897, dice = 0.9110574722290039\n"
=======
            "EP : 77, current_lr = [1.4416052942640093e-05], train_loss = 0.0041, IoU = 0.8987, dice = 0.9461 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.31it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.43it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 30, current_lr = [3.818985058533984e-05] , train loss = 0.003744960769489851 IoU = 0.8634918928146362, dice = 0.9251776933670044\n"
=======
            "EP : 78, current_lr = [1.336950205329221e-05], train_loss = 0.0040, IoU = 0.9025, dice = 0.9483 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.32it/s]\n"
=======
            "100%|| 125/125 [00:52<00:00,  2.39it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 31, current_lr = [3.520365877844025e-05] , train loss = 0.003737437681549983 IoU = 0.8689146041870117, dice = 0.9286245107650757\n"
=======
            "EP : 79, current_lr = [1.2359594482598395e-05], train_loss = 0.0041, IoU = 0.9017, dice = 0.9478 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.27it/s]\n"
=======
            "100%|| 125/125 [00:52<00:00,  2.38it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 32, current_lr = [3.227783464210856e-05] , train loss = 0.0035162474308717286 IoU = 0.872221827507019, dice = 0.9304748773574829\n"
=======
            "EP : 80, current_lr = [1.1387326887403298e-05], train_loss = 0.0043, IoU = 0.9052, dice = 0.9499 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.35it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 33, current_lr = [2.9423925067529e-05] , train loss = 0.0032421181524460692 IoU = 0.876003623008728, dice = 0.9326033592224121\n"
=======
            "EP : 81, current_lr = [1.045365877844009e-05], train_loss = 0.0039, IoU = 0.8988, dice = 0.9462 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.40it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.42it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 34, current_lr = [2.665319313196521e-05] , train loss = 0.003464440328701 IoU = 0.8661473989486694, dice = 0.9267083406448364\n"
=======
            "EP : 82, current_lr = [9.55951157340918e-06], train_loss = 0.0038, IoU = 0.9037, dice = 0.9489 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.32it/s]\n"
=======
            "100%|| 125/125 [00:52<00:00,  2.39it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 35, current_lr = [2.3976573648539775e-05] , train loss = 0.0033623792613590403 IoU = 0.8732646703720093, dice = 0.9309667348861694\n"
=======
            "EP : 83, current_lr = [8.705767687650241e-06], train_loss = 0.0039, IoU = 0.9095, dice = 0.9523 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.40it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 36, current_lr = [2.140463001152267e-05] , train loss = 0.0033086154670898048 IoU = 0.876764178276062, dice = 0.9331033229827881\n"
=======
            "EP : 84, current_lr = [7.893269663304828e-06], train_loss = 0.0040, IoU = 0.9042, dice = 0.9492 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.41it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 37, current_lr = [1.8947512507439936e-05] , train loss = 0.0030174148546177008 IoU = 0.8845117092132568, dice = 0.9376862049102783\n"
=======
            "EP : 85, current_lr = [7.1228193378288065e-06], train_loss = 0.0038, IoU = 0.9094, dice = 0.9522 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.30it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 38, current_lr = [1.6614918256529974e-05] , train loss = 0.003236339621556302 IoU = 0.8840511441230774, dice = 0.937523365020752\n"
=======
            "EP : 86, current_lr = [6.395177052675833e-06], train_loss = 0.0039, IoU = 0.9071, dice = 0.9509 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.30it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 39, current_lr = [1.4416052942640149e-05] , train loss = 0.0030644055139938636 IoU = 0.8853068351745605, dice = 0.9381353855133057\n"
=======
            "EP : 87, current_lr = [5.711060902932073e-06], train_loss = 0.0041, IoU = 0.9078, dice = 0.9513 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.31it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.42it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 40, current_lr = [1.2359594482598444e-05] , train loss = 0.0030499843608898423 IoU = 0.8889873623847961, dice = 0.9403784275054932\n"
=======
            "EP : 88, current_lr = [5.071146028642972e-06], train_loss = 0.0037, IoU = 0.9110, dice = 0.9531 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.36it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.42it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 41, current_lr = [1.045365877844012e-05] , train loss = 0.003166326353537096 IoU = 0.8854815363883972, dice = 0.938292384147644\n"
=======
            "EP : 89, current_lr = [4.4760639485316e-06], train_loss = 0.0036, IoU = 0.9135, dice = 0.9544 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.34it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.42it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 42, current_lr = [8.705767687650275e-06] , train loss = 0.0030049514413500824 IoU = 0.8807594776153564, dice = 0.9354986548423767\n"
=======
            "EP : 90, current_lr = [3.926401936765901e-06], train_loss = 0.0039, IoU = 0.9079, dice = 0.9513 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.40it/s]\n"
=======
            "100%|| 125/125 [00:52<00:00,  2.39it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 43, current_lr = [7.122819337828784e-06] , train loss = 0.0028900720520011547 IoU = 0.8902515172958374, dice = 0.9410350322723389\n"
=======
            "EP : 91, current_lr = [3.422702443389974e-06], train_loss = 0.0037, IoU = 0.9088, dice = 0.9518 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.29it/s]\n"
=======
            "100%|| 125/125 [00:52<00:00,  2.39it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 44, current_lr = [5.711060902932052e-06] , train loss = 0.0029531953914556652 IoU = 0.8954226970672607, dice = 0.9440359473228455\n"
=======
            "EP : 92, current_lr = [2.965462558991402e-06], train_loss = 0.0037, IoU = 0.9089, dice = 0.9518 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.32it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 45, current_lr = [4.476063948531567e-06] , train loss = 0.0030105698304916067 IoU = 0.8893720507621765, dice = 0.9404702186584473\n"
=======
            "EP : 93, current_lr = [2.5551335241328312e-06], train_loss = 0.0038, IoU = 0.9136, dice = 0.9545 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.32it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.42it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 46, current_lr = [3.4227024433899222e-06] , train loss = 0.0028819538752681445 IoU = 0.8900744915008545, dice = 0.9409374594688416\n"
=======
            "EP : 94, current_lr = [2.1921202840320585e-06], train_loss = 0.0039, IoU = 0.9080, dice = 0.9513 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.35it/s]\n"
=======
            "100%|| 125/125 [00:53<00:00,  2.34it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 47, current_lr = [2.555133524132781e-06] , train loss = 0.0027987947521199074 IoU = 0.8989545702934265, dice = 0.9460839629173279\n"
=======
            "EP : 95, current_lr = [1.8767810889299456e-06], train_loss = 0.0039, IoU = 0.9099, dice = 0.9525 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.29it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.42it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 48, current_lr = [1.8767810889299187e-06] , train loss = 0.0028809492290574347 IoU = 0.8898025751113892, dice = 0.9407793283462524\n"
=======
            "EP : 96, current_lr = [1.609427140540712e-06], train_loss = 0.0037, IoU = 0.9108, dice = 0.9529 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.29it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.43it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 49, current_lr = [1.3903222849333511e-06] , train loss = 0.0026604376214977707 IoU = 0.896744966506958, dice = 0.9447811245918274\n"
=======
            "EP : 97, current_lr = [1.390322284933368e-06], train_loss = 0.0037, IoU = 0.9068, dice = 0.9507 \n",
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "100%|| 84/84 [00:19<00:00,  4.34it/s]\n"
=======
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "EP 50, current_lr = [1.0976769428005593e-06] , train loss = 0.0026945688005071133 IoU = 0.9006408452987671, dice = 0.9470443725585938\n"
=======
            "EP : 98, current_lr = [1.2196827521475498e-06], train_loss = 0.0038, IoU = 0.9067, dice = 0.9507 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 99, current_lr = [1.0976769428005625e-06], train_loss = 0.0039, IoU = 0.9066, dice = 0.9505 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 125/125 [00:51<00:00,  2.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP : 100, current_lr = [1.0244252618962874e-06], train_loss = 0.0039, IoU = 0.9065, dice = 0.9505 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
          ]
        }
      ],
      "source": [
<<<<<<< HEAD
=======
        "max_dice = 0.0 \n",
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
        "for ep in range(1, 1+n_eps):\n",
        "    train_loss_meter.reset()\n",
        "    intersection_meter.reset()\n",
        "    union_meter.reset()\n",
        "    target_meter.reset()\n",
        "    model.train()\n",
        "\n",
<<<<<<< HEAD
        "    for batch_id, (x, y) in enumerate(tqdm(train_loader), start=1):\n",
=======
        "    for batch_id, (x, y) in enumerate(tqdm(train_dataloader), start=1):\n",
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
        "        if ep <= 1:\n",
        "            optimizer.param_groups[0][\"lr\"] = (ep * batch_id) / (1.0 * total_step) * init_lr\n",
        "        else:\n",
        "            scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        n = x.shape[0]\n",
        "        x = x.to(device).float()\n",
        "        y = y.to(device).long()\n",
<<<<<<< HEAD
        "        y_hat = model.forward_dummy(x) #(B, C, H, W)\n",
=======
        "        # print(x.shape, y.shape)\n",
        "        \n",
        "        y_hat = model.forward_dummy(x) #(B, C, H, W)\n",
        "        # print(y_hat.shape)\n",
        "\n",
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
        "        loss = criterion(y_hat, y) #(B, C, H, W) >< (B, H, W)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #save metrics\n",
        "        with torch.no_grad():\n",
        "            train_loss_meter.update(loss.item())\n",
        "            y_hat_mask = y_hat.argmax(dim=1).squeeze(1) # (B, C, H, W) -> (B, 1, H, W) -> (B, H, W)\n",
        "            intersection, union, target = intersectionAndUnionGPU(y_hat_mask.float(), y.float(), 3)\n",
        "            intersection_meter.update(intersection)\n",
        "            union_meter.update(union)\n",
        "            target_meter.update(target)\n",
        "\n",
        "    #compute iou, dice\n",
        "    with torch.no_grad():\n",
        "        iou_class = intersection_meter.sum / (union_meter.sum + 1e-10) #vector 3D\n",
        "        dice_class = (2 * intersection_meter.sum) / (intersection_meter.sum + union_meter.sum + 1e-10) #vector 3D\n",
        "\n",
        "        mIoU = torch.mean(iou_class[1:]) #mean iou class 1 and class 2\n",
        "        mDice = torch.mean(dice_class[1:]) #mean dice class 1 and class 2\n",
        "\n",
<<<<<<< HEAD
        "    print(\"EP {}, current_lr = {} , train loss = {} IoU = {}, dice = {}\".format(ep, scheduler.get_last_lr(), train_loss_meter.avg, mIoU, mDice))\n",
        "\n",
        "    if ep >= 40:\n",
        "        torch.save(model.state_dict(), \"./train_weights/modelSegFormer_ep_{}.pth\".format(ep))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "REv75reBwOiJ"
      },
      "outputs": [],
      "source": [
        "color_dict = {0: (0,   0, 0),\n",
        "              1: (0, 255,   0),\n",
        "              2: (0, 0,   255)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UXcmd_AmwVkC"
      },
      "outputs": [],
      "source": [
        "def mask_to_rgb(mask, color_dict):\n",
        "    output = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
        "    for k in color_dict.keys():\n",
        "        output[mask==k] = color_dict[k]\n",
        "    return np.uint8(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6SIkocJlwZoE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory test_mask: File exists\n",
            "mkdir: cannot create directory test_overlapmask: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir test_mask\n",
        "!mkdir test_overlapmask"
=======
        "    print(f\"EP : {ep}, current_lr = {scheduler.get_last_lr()}, train_loss = {train_loss_meter.avg:.4f}, IoU = {mIoU:.4f}, dice = {mDice:.4f} \\n\")\n",
        "\n",
        "    if mDice > max_dice:\n",
        "        max_dice = mDice\n",
        "        torch.save(model.state_dict(), f\"{save_path}/weights/best_dice_ckpt_ep_{ep}.pth\")"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 15,
      "metadata": {
        "id": "N7X4erIewemH"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "for file in sorted(glob(\"/home/pervinco/Datasets/BKAI_IGH_NeoPolyp/test/*\")):\n",
        "    file_name = file.split(\"/\")[-1].split('.')[0]\n",
        "    ori_img = cv2.imread(file)\n",
        "    ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n",
        "    ori_w = ori_img.shape[0]\n",
        "    ori_h = ori_img.shape[1]\n",
        "    img = cv2.resize(ori_img, (trainsize, trainsize))\n",
        "    transformed = val_transform(image=img)\n",
        "    input_img = transformed[\"image\"]\n",
        "    input_img = input_img.unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "      output_mask = model.forward_dummy(input_img).squeeze(0).cpu().numpy().transpose(1,2,0)\n",
        "    mask = cv2.resize(output_mask, (ori_h, ori_w))\n",
        "    mask = np.argmax(mask, axis=-1)\n",
        "    new_rgb_mask = np.zeros((*mask.shape, 3)).astype(np.uint8)\n",
        "    mask_rgb = mask_to_rgb(mask, color_dict)\n",
        "    mask_rgb_true = cv2.cvtColor(mask_rgb, cv2.COLOR_BGR2RGB)\n",
        "    overlap = 0.7*ori_img+0.3*mask_rgb_true\n",
        "    overlap = overlap.astype('uint8')\n",
        "    overlap = cv2.cvtColor(overlap, cv2.COLOR_RGB2BGR)\n",
        "    cv2.imwrite(f\"./test_mask/{file_name}.jpeg\", mask_rgb)\n",
        "    cv2.imwrite(f\"./test_overlapmask/{file_name}.jpeg\", overlap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "z5Fb-Kmuw1dU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./test_mask/c4be73749a0d21db70dd094a7f32574d.jpeg\n",
            "./test_mask/02fa602bb3c7abacdbd7e6afd56ea7bc.jpeg\n",
            "./test_mask/3425b976973f13dd311a65d2b46d0a60.jpeg\n",
            "./test_mask/a15fc656702fa602bb3c7abacdbd7e6a.jpeg\n",
            "./test_mask/c695325ded465efde988dfb96d081533.jpeg\n",
            "./test_mask/f8e26031fbb5e52c41545ba55aadaa77.jpeg\n",
            "./test_mask/6f4d4987ea3b4bae5672a230194c5a08.jpeg\n",
            "./test_mask/7af2ed9fbb63b28163a745959c039830.jpeg\n",
            "./test_mask/6d3694abb47953b0e4909384b57bb6a0.jpeg\n",
            "./test_mask/782707d7c359e27888daefee82519763.jpeg\n",
            "./test_mask/019410b1fcf0625f608b4ce97629ab55.jpeg\n",
            "./test_mask/f62f215f0da4ad3a7ab8df9da7386835.jpeg\n",
            "./test_mask/5a51625559c7e610b1531871f2fd85a0.jpeg\n",
            "./test_mask/ff05dec1eb3a70b145a7d8d3b6c0ed75.jpeg\n",
            "./test_mask/39dda50f954ba59c7de13a35276a4764.jpeg\n",
            "./test_mask/af35b65bd9ea42cfcfedb5eb2a0e4b50.jpeg\n",
            "./test_mask/fcd6da15fc656702fa602bb3c7abacdb.jpeg\n",
            "./test_mask/60a633a8d5b2b2b55157b7781e2c706c.jpeg\n",
            "./test_mask/3c692195f853af7f8a4df1ec859759b7.jpeg\n",
            "./test_mask/45b21960c94b0aab4c024a573c692195.jpeg\n",
            "./test_mask/fb905b78a91391adc0bb223c4eaf3372.jpeg\n",
            "./test_mask/e1e0ae936de314f2d95e6c487ffa651b.jpeg\n",
            "./test_mask/625559c7e610b1531871f2fd85a04fae.jpeg\n",
            "./test_mask/f14e1e0ae936de314f2d95e6c487ffa6.jpeg\n",
            "./test_mask/e19769fa2d37d32780fd497e1c0e9082.jpeg\n",
            "./test_mask/425b976973f13dd311a65d2b46d0a608.jpeg\n",
            "./test_mask/dd78294679c9cbb2a365b5574868eb60.jpeg\n",
            "./test_mask/7f32574d6c748c41743c6c08a1d1ad8f.jpeg\n",
            "./test_mask/9fc7330398846f67b5df7cdf3f33c3ca.jpeg\n",
            "./test_mask/0a5f3601ad4f13ccf1f4b331a412fc44.jpeg\n",
            "./test_mask/80cae6daedd989517cb8041ed86e5822.jpeg\n",
            "./test_mask/8eb5a9a8a8d7fcc9df8e5ad89d284483.jpeg\n",
            "./test_mask/66e057db382b8564872a27301a654864.jpeg\n",
            "./test_mask/4baddc22268d4b4ef4d95ceea1195799.jpeg\n",
            "./test_mask/cb1b387133b51209db6dcdda5cc8a788.jpeg\n",
            "./test_mask/a6e51d077bad31c8c5f54ffaa27a6235.jpeg\n",
            "./test_mask/97e1c0e9082ea2c193ac8d551c149b60.jpeg\n",
            "./test_mask/88e16d4ca6160127cd1d5ff99c267599.jpeg\n",
            "./test_mask/db5eb2a0e4b50889d874c68c030b9afe.jpeg\n",
            "./test_mask/8395e56a6d9ba9d45c3dbc695325ded4.jpeg\n",
            "./test_mask/4e8bfb905b78a91391adc0bb223c4eaf.jpeg\n",
            "./test_mask/df8e26031fbb5e52c41545ba55aadaa7.jpeg\n",
            "./test_mask/a51625559c7e610b1531871f2fd85a04.jpeg\n",
            "./test_mask/bec33b5e3d68f9d4c331587f9b9d49e2.jpeg\n",
            "./test_mask/f13dd311a65d2b46d0a6085835c525af.jpeg\n",
            "./test_mask/559c7e610b1531871f2fd85a04faeeb2.jpeg\n",
            "./test_mask/8cbdf366e057db382b8564872a27301a.jpeg\n",
            "./test_mask/68d4b4ef4d95ceea11957998906d3694.jpeg\n",
            "./test_mask/5e8f14e1e0ae936de314f2d95e6c487f.jpeg\n",
            "./test_mask/8fa8625605da2023387fd56c04414eaa.jpeg\n",
            "./test_mask/c193ac8d551c149b60f2965341caf528.jpeg\n",
            "./test_mask/c656702fa602bb3c7abacdbd7e6afd56.jpeg\n",
            "./test_mask/80c643782707d7c359e27888daefee82.jpeg\n",
            "./test_mask/e3c84417fda8019410b1fcf0625f608b.jpeg\n",
            "./test_mask/285e26c90e1797c77826f9a7021bab9f.jpeg\n",
            "./test_mask/82ea2c193ac8d551c149b60f2965341c.jpeg\n",
            "./test_mask/633a8d5b2b2b55157b7781e2c706c75c.jpeg\n",
            "./test_mask/4417fda8019410b1fcf0625f608b4ce9.jpeg\n",
            "./test_mask/2d9e593b6be1ac29adbe86f03d900fd1.jpeg\n",
            "./test_mask/7ad1cf2eb9d32a3dc907950289e976c7.jpeg\n",
            "./test_mask/9c7976c1182df0de51d32128c358d1fd.jpeg\n",
            "./test_mask/3bbc04a3afe1f119f21b248d152b672a.jpeg\n",
            "./test_mask/c7e610b1531871f2fd85a04faeeb2b53.jpeg\n",
            "./test_mask/85a04faeeb2b535797395305af926a6f.jpeg\n",
            "./test_mask/6231002ec4a1fe748f3085f1ce88cbdf.jpeg\n",
            "./test_mask/7330398846f67b5df7cdf3f33c3ca4d5.jpeg\n",
            "./test_mask/a48847ae8395e56a6d9ba9d45c3dbc69.jpeg\n",
            "./test_mask/87133b51209db6dcdda5cc8a788edaeb.jpeg\n",
            "./test_mask/c22268d4b4ef4d95ceea11957998906d.jpeg\n",
            "./test_mask/41ed86e58224cb76a67d4dcf9596154e.jpeg\n",
            "./test_mask/60b246359c68c836f843dcf41f4dce3c.jpeg\n",
            "./test_mask/94a7f32574d6c748c41743c6c08a1d1a.jpeg\n",
            "./test_mask/a3657e4314fe384eb2ba3adfda6c1899.jpeg\n",
            "./test_mask/a9d45c3dbc695325ded465efde988dfb.jpeg\n",
            "./test_mask/936de314f2d95e6c487ffa651b477422.jpeg\n",
            "./test_mask/b21960c94b0aab4c024a573c692195f8.jpeg\n",
            "./test_mask/71f2fd85a04faeeb2b535797395305af.jpeg\n",
            "./test_mask/2cd066b9fdbc3bbc04a3afe1f119f21b.jpeg\n",
            "./test_mask/0626ab4ec3d46e602b296cc5cfd263f1.jpeg\n",
            "./test_mask/cbb2a365b5574868eb60861ee1ff0b8a.jpeg\n",
            "./test_mask/13dd311a65d2b46d0a6085835c525af6.jpeg\n",
            "./test_mask/3c84417fda8019410b1fcf0625f608b4.jpeg\n",
            "./test_mask/3dd311a65d2b46d0a6085835c525af63.jpeg\n",
            "./test_mask/998906d3694abb47953b0e4909384b57.jpeg\n",
            "./test_mask/0a0317371a966bf4b3466463a3c64db1.jpeg\n",
            "./test_mask/692195f853af7f8a4df1ec859759b7c8.jpeg\n",
            "./test_mask/e4a17af18f72c8e6166a915669c99390.jpeg\n",
            "./test_mask/98da48d679d7c7c8d3d96fb2b87fbbcf.jpeg\n",
            "./test_mask/dc70626ab4ec3d46e602b296cc5cfd26.jpeg\n",
            "./test_mask/e1797c77826f9a7021bab9fc73303988.jpeg\n",
            "./test_mask/df366e057db382b8564872a27301a654.jpeg\n",
            "./test_mask/aeeb2b535797395305af926a6f23c5d6.jpeg\n",
            "./test_mask/1209db6dcdda5cc8a788edaeb6aa460a.jpeg\n",
            "./test_mask/eecd70ebce6347c491b37c8c2e5a64a8.jpeg\n",
            "./test_mask/5026b3550534bca540e24f489284b8e6.jpeg\n",
            "./test_mask/dc0bb223c4eaf3372eae567c94ea04c6.jpeg\n",
            "./test_mask/5664c1711b62f15ec83b97bb11e8e0c4.jpeg\n",
            "./test_mask/5c1346e62522325c1b9c4fc9cbe1eca1.jpeg\n",
            "./test_mask/54ba59c7de13a35276a476420655433a.jpeg\n",
            "./test_mask/27738677a6b1f2c6d40b3bbba8f6c704.jpeg\n",
            "./test_mask/4c1711b62f15ec83b97bb11e8e0c4416.jpeg\n",
            "./test_mask/d5060a633a8d5b2b2b55157b7781e2c7.jpeg\n",
            "./test_mask/fdbc3bbc04a3afe1f119f21b248d152b.jpeg\n",
            "./test_mask/63b8318ecf467d7ad048df39beb17636.jpeg\n",
            "./test_mask/d077bad31c8c5f54ffaa27a623511c38.jpeg\n",
            "./test_mask/7fda8019410b1fcf0625f608b4ce9762.jpeg\n",
            "./test_mask/1b62f15ec83b97bb11e8e0c4416c1931.jpeg\n",
            "./test_mask/4ca6160127cd1d5ff99c267599fc487b.jpeg\n",
            "./test_mask/391adc0bb223c4eaf3372eae567c94ea.jpeg\n",
            "./test_mask/0398846f67b5df7cdf3f33c3ca4d5060.jpeg\n",
            "./test_mask/8954bb13d3727c7e5e1069646f2f0bb8.jpeg\n",
            "./test_mask/ad43fe2cd066b9fdbc3bbc04a3afe1f1.jpeg\n",
            "./test_mask/dd094a7f32574d6c748c41743c6c08a1.jpeg\n",
            "./test_mask/1ad4f13ccf1f4b331a412fc44655fb51.jpeg\n",
            "./test_mask/cf464aa36bf7c09a3bb0e5ca159410b9.jpeg\n",
            "./test_mask/afe1f119f21b248d152b672ab3492fc6.jpeg\n",
            "./test_mask/3b8318ecf467d7ad048df39beb176363.jpeg\n",
            "./test_mask/6240619ebebe9e9c9d00a4262b4fe4a5.jpeg\n",
            "./test_mask/aafac813fe3ccba3e032dd2948a80c64.jpeg\n",
            "./test_mask/ff55177a34fc01019eec999fd84e679b.jpeg\n",
            "./test_mask/5beb48f0be11d0309d1dff09b8405734.jpeg\n",
            "./test_mask/ca4d5060a633a8d5b2b2b55157b7781e.jpeg\n",
            "./test_mask/26679bff55177a34fc01019eec999fd8.jpeg\n",
            "./test_mask/30c2f4fc276ed9f178dc2f4af6266509.jpeg\n",
            "./test_mask/d6240619ebebe9e9c9d00a4262b4fe4a.jpeg\n",
            "./test_mask/be4d18d5401f659532897255ce2dd4ae.jpeg\n",
            "./test_mask/343f27ebc5d92b9076135d76d0bbd4ce.jpeg\n",
            "./test_mask/2a365b5574868eb60861ee1ff0b8a4f6.jpeg\n",
            "./test_mask/05734fbeedd0f9da760db74a29abdb04.jpeg\n",
            "./test_mask/cdf3f33c3ca4d5060a633a8d5b2b2b55.jpeg\n",
            "./test_mask/ea42b4eebc9e5a87e443434ac60af150.jpeg\n",
            "./test_mask/e8bfb905b78a91391adc0bb223c4eaf3.jpeg\n",
            "./test_mask/6ad1468996b4a9ce6d840b53a6558038.jpeg\n",
            "./test_mask/d6bf62f215f0da4ad3a7ab8df9da7386.jpeg\n",
            "./test_mask/cf6644589e532a9ee954f81faedbce39.jpeg\n",
            "./test_mask/395e56a6d9ba9d45c3dbc695325ded46.jpeg\n",
            "./test_mask/0af3feff05dec1eb3a70b145a7d8d3b6.jpeg\n",
            "./test_mask/461c2a337948a41964c1d4f50a5f3601.jpeg\n",
            "./test_mask/d694539ef2424a9218697283baa3657e.jpeg\n",
            "./test_mask/7cb2eb1ef57af2ed9fbb63b28163a745.jpeg\n",
            "./test_mask/e5e8f14e1e0ae936de314f2d95e6c487.jpeg\n",
            "./test_mask/268d4b4ef4d95ceea11957998906d369.jpeg\n",
            "./test_mask/05b78a91391adc0bb223c4eaf3372eae.jpeg\n",
            "./test_mask/1531871f2fd85a04faeeb2b535797395.jpeg\n",
            "./test_mask/1db239dda50f954ba59c7de13a35276a.jpeg\n",
            "./test_mask/8b8ec74baddc22268d4b4ef4d95ceea1.jpeg\n",
            "./test_mask/50534bca540e24f489284b8e6953ad88.jpeg\n",
            "./test_mask/15fc656702fa602bb3c7abacdbd7e6af.jpeg\n",
            "./test_mask/faef7fdb2d45b21960c94b0aab4c024a.jpeg\n",
            "./test_mask/e73749a0d21db70dd094a7f32574d6c7.jpeg\n",
            "./test_mask/a6d9ba9d45c3dbc695325ded465efde9.jpeg\n",
            "./test_mask/cb2eb1ef57af2ed9fbb63b28163a7459.jpeg\n",
            "./test_mask/4f437f0019f7e6af7d7147763bdfb928.jpeg\n",
            "./test_mask/3c3ca4d5060a633a8d5b2b2b55157b77.jpeg\n",
            "./test_mask/eb1ef57af2ed9fbb63b28163a745959c.jpeg\n",
            "./test_mask/677a6b1f2c6d40b3bbba8f6c704801b3.jpeg\n",
            "./test_mask/5b21960c94b0aab4c024a573c692195f.jpeg\n",
            "./test_mask/7cdf3f33c3ca4d5060a633a8d5b2b2b5.jpeg\n",
            "./test_mask/f8e5ad89d2844837f2a0f1536ad3f6a5.jpeg\n",
            "./test_mask/314fe384eb2ba3adfda6c1899fdc9837.jpeg\n",
            "./test_mask/318ecf467d7ad048df39beb176363408.jpeg\n",
            "./test_mask/780fd497e1c0e9082ea2c193ac8d551c.jpeg\n",
            "./test_mask/e7998934d417cb2eb1ef57af2ed9fbb6.jpeg\n",
            "./test_mask/710d568df17586ad8f3297c819c90895.jpeg\n",
            "./test_mask/3f33c3ca4d5060a633a8d5b2b2b55157.jpeg\n",
            "./test_mask/6ddca6ee1af35b65bd9ea42cfcfedb5e.jpeg\n",
            "./test_mask/e2cd066b9fdbc3bbc04a3afe1f119f21.jpeg\n",
            "./test_mask/4e2a6e51d077bad31c8c5f54ffaa27a6.jpeg\n",
            "./test_mask/b70dd094a7f32574d6c748c41743c6c0.jpeg\n",
            "./test_mask/eff05dec1eb3a70b145a7d8d3b6c0ed7.jpeg\n",
            "./test_mask/2ed9fbb63b28163a745959c03983064a.jpeg\n",
            "./test_mask/9632a3c6f7f7fb2a643f15bd0249ddcc.jpeg\n",
            "./test_mask/0619ebebe9e9c9d00a4262b4fe4a5a95.jpeg\n",
            "./test_mask/d3694abb47953b0e4909384b57bb6a05.jpeg\n",
            "./test_mask/626650908b1cb932a767bf5487ced51b.jpeg\n",
            "./test_mask/f7fdb2d45b21960c94b0aab4c024a573.jpeg\n",
            "./test_mask/72d9e593b6be1ac29adbe86f03d900fd.jpeg\n",
            "./test_mask/3657e4314fe384eb2ba3adfda6c1899f.jpeg\n",
            "./test_mask/39d6aad6bb0170a40ed32deef71fbe08.jpeg\n",
            "./test_mask/be86f03d900fd197cd955fa095f97845.jpeg\n",
            "./test_mask/7b5df7cdf3f33c3ca4d5060a633a8d5b.jpeg\n",
            "./test_mask/c5a0808bee60b246359c68c836f843dc.jpeg\n",
            "./test_mask/77e004e8bfb905b78a91391adc0bb223.jpeg\n",
            "./test_mask/67d4dcf9596154efb7cef748d9cbd617.jpeg\n",
            "./test_mask/1c0e9082ea2c193ac8d551c149b60f29.jpeg\n",
            "./test_mask/fe1f119f21b248d152b672ab3492fc62.jpeg\n",
            "./test_mask/e56a6d9ba9d45c3dbc695325ded465ef.jpeg\n",
            "./test_mask/6b83ef461c2a337948a41964c1d4f50a.jpeg\n",
            "./test_mask/1002ec4a1fe748f3085f1ce88cbdf366.jpeg\n",
            "./test_mask/0fca6a4248a41e8db8b4ed633b456aaa.jpeg\n",
            "./test_mask/7936140a2d5fc1443c4e445927738677.jpeg\n",
            "./test_mask/4fda8daadc8dd23ae214d84b5dec33fd.jpeg\n",
            "./test_mask/6679bff55177a34fc01019eec999fd84.jpeg\n",
            "./test_mask/c41545ba55aadaa77712a48e11d579d9.jpeg\n",
            "./test_mask/6f67b5df7cdf3f33c3ca4d5060a633a8.jpeg\n",
            "./test_mask/e9082ea2c193ac8d551c149b60f29653.jpeg\n",
            "./test_mask/4ef4d95ceea11957998906d3694abb47.jpeg\n",
            "./test_mask/7f0019f7e6af7d7147763bdfb928d788.jpeg\n",
            "./test_mask/a6a4248a41e8db8b4ed633b456aaafac.jpeg\n",
            "./test_mask/cc5cfd263f1f90be28799235026b3550.jpeg\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m        Kernel .       .    <a href='https://aka.ms/vscodeJupyterKernelCrash'>  </a>  .   Jupyter <a href='command:jupyter.viewOutput'></a> ."
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def rle_to_string(runs):\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "\n",
        "def rle_encode_one_mask(mask):\n",
        "    pixels = mask.flatten()\n",
        "    pixels[pixels > 225] = 255\n",
        "    pixels[pixels <= 225] = 0\n",
        "    use_padding = False\n",
        "    if pixels[0] or pixels[-1]:\n",
        "        use_padding = True\n",
        "        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n",
        "        pixel_padded[1:-1] = pixels\n",
        "        pixels = pixel_padded\n",
        "    \n",
        "    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
        "    if use_padding:\n",
        "        rle = rle - 1\n",
        "    rle[1::2] = rle[1::2] - rle[:-1:2]\n",
        "    return rle_to_string(rle)\n",
        "\n",
        "def rle2mask(mask_rle, shape=(3,3)):\n",
        "    '''\n",
        "    mask_rle: run-length as string formated (start length)\n",
        "    shape: (width,height) of array to return \n",
        "    Returns numpy array, 1 - mask, 0 - background\n",
        "\n",
        "    '''\n",
        "    s = mask_rle.split()\n",
        "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
        "    starts -= 1\n",
        "    ends = starts + lengths\n",
        "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
        "    for lo, hi in zip(starts, ends):\n",
        "        img[lo:hi] = 1\n",
        "    return img.reshape(shape).T\n",
        "\n",
        "def mask2string(dir):\n",
        "    ## mask --> string\n",
        "    strings = []\n",
        "    ids = []\n",
        "    ws, hs = [[] for i in range(2)]\n",
        "    for image_id in os.listdir(dir):\n",
        "        id = image_id.split('.')[0]\n",
        "        path = os.path.join(dir, image_id)\n",
        "        print(path)\n",
        "        img = cv2.imread(path)[:,:,::-1]\n",
        "        h, w = img.shape[0], img.shape[1]\n",
        "        for channel in range(2):\n",
        "            ws.append(w)\n",
        "            hs.append(h)\n",
        "            ids.append(f'{id}_{channel}')\n",
        "            string = rle_encode_one_mask(img[:,:,channel])\n",
        "            strings.append(string)\n",
        "    r = {\n",
        "        'ids': ids,\n",
        "        'strings': strings,\n",
        "    }\n",
        "    return r\n",
        "\n",
        "\n",
        "MASK_DIR_PATH = './test_mask' # change this to the path to your output mask folder\n",
        "dir = MASK_DIR_PATH\n",
        "res = mask2string(dir)\n",
        "df = pd.DataFrame(columns=['Id', 'Expected'])\n",
        "df['Id'] = res['ids']\n",
        "df['Expected'] = res['strings']\n",
        "\n",
        "df.to_csv(r'output.csv', index=False)"
      ]
=======
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
<<<<<<< HEAD
      "version": "3.8.10"
=======
      "version": "3.10.13"
>>>>>>> e0d44c7e27da0ff293b0125ccc9fbc1ec7ea7520
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
